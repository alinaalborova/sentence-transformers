{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentence-embeddings.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alinaalborova/sentence-transformers/blob/master/sentence_embeddings_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLeV1Uy2-itV",
        "colab_type": "code",
        "outputId": "cef1bb2b-74e8-48ce-d2bb-2fc5b634bcc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        }
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/91/c85ddef872d5bb39949386930c1f834ac382e145fcd30155b09d6fb65c5a/sentence-transformers-0.2.5.tar.gz (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.3MB/s \n",
            "\u001b[?25hCollecting transformers==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 19.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (1.11.14)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.15.0,>=1.14.14 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (1.14.14)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (0.9.4)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0->sentence-transformers) (7.0)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.14->boto3->transformers==2.3.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.14->boto3->transformers==2.3.0->sentence-transformers) (2.6.1)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.5-cp36-none-any.whl size=64942 sha256=ad1d1c5d3fddca7b83ffb10f02586c53707f34334855a00fcd1694b9e255f03f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/ce/39/5bbda8ac34eb52df8c6531382ca077773fbfcbfb6386e5d66c\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=157bf9fef03d5e7510e67e8897b266a71f5d31cf9f2dc5828de99394e46e60e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.38 sentence-transformers-0.2.5 sentencepiece-0.1.85 transformers-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_73o_OhV4lQy",
        "colab_type": "code",
        "outputId": "eed40f24-a0cc-40eb-b376-94b1a737ccbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!pip install h5py pyyaml"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73ps5AR44n4t",
        "colab_type": "code",
        "outputId": "05c7c73b-94ef-4ecc-fbca-627409b94ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT4xn5PD_B4_",
        "colab_type": "code",
        "outputId": "90f0059c-b448-4fa9-abe9-2514af9ef7c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:09<00:00, 44.0MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1MJnL5W_JKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = ['This framework generates embeddings for each input sentence',\n",
        "    'Sentences are passed as a list of string.', \n",
        "    'The quick brown fox jumps over the lazy dog.']\n",
        "sentence_embeddings = model.encode(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3RT3x-f_Pvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "65808483-b5b2-40b8-e7b0-c39c57eb8724"
      },
      "source": [
        "for sentence, embedding in zip(sentences, sentence_embeddings):\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding:\", len(embedding), embedding[:10])\n",
        "    print(\"\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: This framework generates embeddings for each input sentence\n",
            "Embedding: 768 [-0.10409461  0.5274767   1.1797731   0.1943656   0.15911378  0.5455504\n",
            "  0.28180975  0.12159034  0.2919682  -0.33685794]\n",
            "\n",
            "Sentence: Sentences are passed as a list of string.\n",
            "Embedding: 768 [-0.13118416 -0.17390303  1.1052188   0.2485417   0.04100098  0.4031433\n",
            " -0.38167286  0.17468336 -0.5365205   0.35700977]\n",
            "\n",
            "Sentence: The quick brown fox jumps over the lazy dog.\n",
            "Embedding: 768 [-0.7489929   0.718918   -1.0394567   0.06408808  0.0507046  -0.72906154\n",
            " -0.37650546 -0.35532475 -0.3260921  -0.85205364]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsXovfJm_SFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_embeddings = model.encode(['Мама мыла раму'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VjfgQmt_b6W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "769694d9-6aac-4fc6-c495-5e7d7086983e"
      },
      "source": [
        "rus_sentences = ['мама мыла раму', 'рама мыла маму']\n",
        "rus_sentences_embeddings = model.encode(rus_sentences)\n",
        "for sentence, embedding in zip(rus_sentences, rus_sentences_embeddings):\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding:\", len(embedding), embedding[:10])\n",
        "    print(\"\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: мама мыла раму\n",
            "Embedding: 768 [ 0.0241819   0.18126716  1.2029921   0.04019685  0.88401204  0.50684255\n",
            "  0.28139952  0.49990663 -0.382687    0.39505315]\n",
            "\n",
            "Sentence: рама мыла маму\n",
            "Embedding: 768 [ 0.01930088  0.15019126  1.1643056   0.05611547  0.831827    0.5418703\n",
            "  0.2924843   0.5805236  -0.36399814  0.33721396]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oILRpQJK_s-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "outputId": "c576b748-d1c1-49b2-b9d7-2045b58ed29d"
      },
      "source": [
        "de_sentences = ['Mein Hund ist gross', 'Meine Katze ist gross', 'Mein Hund ist klein', 'Dein Hund ist klein', 'Dein Hund ist gross', 'Meine Katze ist klein', 'Deine Katze ist klein', 'Deine Katze ist gross']\n",
        "de_sentences_embeddings = model.encode(de_sentences)\n",
        "for sentence, embedding in zip(de_sentences, de_sentences_embeddings):\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding:\", len(embedding), embedding[:10])\n",
        "    print(\"\")    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: Mein Hund ist gross\n",
            "Embedding: 768 [-0.68678635  0.59580314  1.9084395   0.9460536   0.41467732 -0.42681608\n",
            "  1.3322651   0.5314361   0.5306038  -0.27077362]\n",
            "\n",
            "Sentence: Meine Katze ist gross\n",
            "Embedding: 768 [-0.60223436  0.545313    1.9917421   0.9135116   0.46526688 -0.2666106\n",
            "  1.3437458   0.6296467   0.43946704 -0.561631  ]\n",
            "\n",
            "Sentence: Mein Hund ist klein\n",
            "Embedding: 768 [-0.64887303  0.5054074   1.0070063   0.50670886  0.5015641  -0.14005348\n",
            "  0.6857614   0.6072325   0.12251331 -0.04573577]\n",
            "\n",
            "Sentence: Dein Hund ist klein\n",
            "Embedding: 768 [-0.68739915  0.4467606   1.0210818   0.45596883  0.4509566  -0.12971541\n",
            "  0.5855655   0.73438096  0.33062404 -0.05218401]\n",
            "\n",
            "Sentence: Dein Hund ist gross\n",
            "Embedding: 768 [-0.7344738   0.48957378  1.9711405   0.8961794   0.42524046 -0.5017001\n",
            "  1.227957    0.5796358   0.72149193 -0.28928864]\n",
            "\n",
            "Sentence: Meine Katze ist klein\n",
            "Embedding: 768 [-0.4702195   0.46054116  1.1939263   0.46024305  0.4444208  -0.05121205\n",
            "  0.7456373   0.6947272   0.05512178 -0.30690143]\n",
            "\n",
            "Sentence: Deine Katze ist klein\n",
            "Embedding: 768 [-0.54005337  0.20803958  1.0342693   0.4123463   0.5320553  -0.05591041\n",
            "  0.6717732   0.69248307  0.12748083 -0.3033148 ]\n",
            "\n",
            "Sentence: Deine Katze ist gross\n",
            "Embedding: 768 [-0.67345417  0.3218871   1.9589813   0.9395846   0.61661166 -0.2975253\n",
            "  1.1712592   0.63571405  0.50444216 -0.58294135]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5-RxFX6tCra",
        "colab_type": "text"
      },
      "source": [
        "# FAISS Installation\n",
        "\n",
        "Sadly, it can be painfull :(\n",
        "\n",
        "In according to answer from SO: https://stackoverflow.com/questions/47967252/installing-faiss-on-google-colaboratory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWJMV4xZAFXV",
        "colab_type": "code",
        "outputId": "ce6bef9c-3cb9-4b5c-8890-377835bd8d08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#!wget  https://anaconda.org/pytorch/faiss-cpu/1.2.1/download/linux-64/faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "#!tar xvjf faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "!wget https://anaconda.org/pytorch/faiss-gpu/1.2.1/download/linux-64/faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "!tar xvjf faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-14 09:38:21--  https://anaconda.org/pytorch/faiss-gpu/1.2.1/download/linux-64/faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
            "Resolving anaconda.org (anaconda.org)... 104.17.93.24, 104.17.92.24, 2606:4700::6811:5d18, ...\n",
            "Connecting to anaconda.org (anaconda.org)|104.17.93.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://binstar-cio-packages-prod.s3.amazonaws.com/5a15c9cc393ec612061f033a/5ac54beae586bb11ec0ace46?response-content-disposition=attachment%3B%20filename%3D%22faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2%22%3B%20filename%2A%3DUTF-8%27%27faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2&response-content-type=application%2Fx-tar&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=60&X-Amz-Date=20200214T093822Z&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjELr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIBZoB6HBSddl7%2F5jhIT8TClcWppOE%2BwXzJZCg2cK342zAiEAmguME%2F4A1JdTQk6Bk0eyj0HcxJtaqpL37o3Tn5a8fukqtAMIchAAGgw0NTU4NjQwOTgzNzgiDBKYCSeF6Mnq2gOz4yqRA355LieTPx2%2FiqQwOQG8Vsc8ha6ry9JRHlRS6uQVJnXn%2B2SCTZ2g8FcJjyCt4%2B%2B9lHk35S0P63PZCnU4VEJz5%2FJR1LpjRDswn6hTGRNaep%2FgaW1WbYmb%2Bd%2BnvBNHEXTHJxWOxQb0gFSVVJ%2BnDxp4%2F4owAjLQTd86%2FTbhzmbBOf%2FiJNqF%2BkXpC8aBkZ3dwZyv%2BXyNxsopFtPcAyoUYzdTUS3ZNNWNB0zf6tv6JAzl2pig6awn%2BCo1OWEDbS30fAl9cLrEG1CEFMcuqZMlI7Ug7hb%2F6%2BY7F1FgNyLE0hWk61mmvQxXxavBrlzpMnAS%2Bux6PgBAqmgbKbfwJilgpeFT6Gqn6lCH6RO2GFmMKQ6ThrT5mG1JrmAKd9YkRllx3ewUW8X5OTibNY3uziGruO86sZXYetEaVLXkbtp9ADYX5O0%2FfCwuFSwGJMSa9%2BdgQeAqVKoD59K4XYyZ7CUA7TTBe%2FeGHkt4IBpDaJjxwaF5H9WMpCf%2BpFLVQu2fSum2VYHqZUonT8rKpA2PquASLpbukSF3MMLImfIFOusBV8q8VVps4lFQBbNoJK3UpQQa8ixQmGORfB%2BWMH0rbYQLBak4Gwzh35mez%2FKKOwaVheh7zB31C5Aixb564%2B2GBSpyeEpNymJcQA5St%2BJfe1UaNjN3teNzAjINAkOYUDRsBfnx2UAtvXtDZJKlTGDriBpXnGAAcaGryyF4QQzt1vOzUMsR4Db%2BzWOTgjTBWmdFK9DS%2FAholYvk2us1Ub3Gsv6d1aTcWraLjsnQe6apDGwHOnzDcdOiO7aZ0DdKOMnE1FwtWSr1V1k8M3X8Don2cEkn6p2J3MntpPsG9r%2BuA%2FCuATJKMtvDgEq1oQ%3D%3D&X-Amz-Credential=ASIAWUI46DZFFFQZCLPJ%2F20200214%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=3e4ccfb782206018f9490e36e47f18b0877a7b6af18b7c4146e135b60d15056c [following]\n",
            "--2020-02-14 09:38:22--  https://binstar-cio-packages-prod.s3.amazonaws.com/5a15c9cc393ec612061f033a/5ac54beae586bb11ec0ace46?response-content-disposition=attachment%3B%20filename%3D%22faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2%22%3B%20filename%2A%3DUTF-8%27%27faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2&response-content-type=application%2Fx-tar&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=60&X-Amz-Date=20200214T093822Z&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjELr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIBZoB6HBSddl7%2F5jhIT8TClcWppOE%2BwXzJZCg2cK342zAiEAmguME%2F4A1JdTQk6Bk0eyj0HcxJtaqpL37o3Tn5a8fukqtAMIchAAGgw0NTU4NjQwOTgzNzgiDBKYCSeF6Mnq2gOz4yqRA355LieTPx2%2FiqQwOQG8Vsc8ha6ry9JRHlRS6uQVJnXn%2B2SCTZ2g8FcJjyCt4%2B%2B9lHk35S0P63PZCnU4VEJz5%2FJR1LpjRDswn6hTGRNaep%2FgaW1WbYmb%2Bd%2BnvBNHEXTHJxWOxQb0gFSVVJ%2BnDxp4%2F4owAjLQTd86%2FTbhzmbBOf%2FiJNqF%2BkXpC8aBkZ3dwZyv%2BXyNxsopFtPcAyoUYzdTUS3ZNNWNB0zf6tv6JAzl2pig6awn%2BCo1OWEDbS30fAl9cLrEG1CEFMcuqZMlI7Ug7hb%2F6%2BY7F1FgNyLE0hWk61mmvQxXxavBrlzpMnAS%2Bux6PgBAqmgbKbfwJilgpeFT6Gqn6lCH6RO2GFmMKQ6ThrT5mG1JrmAKd9YkRllx3ewUW8X5OTibNY3uziGruO86sZXYetEaVLXkbtp9ADYX5O0%2FfCwuFSwGJMSa9%2BdgQeAqVKoD59K4XYyZ7CUA7TTBe%2FeGHkt4IBpDaJjxwaF5H9WMpCf%2BpFLVQu2fSum2VYHqZUonT8rKpA2PquASLpbukSF3MMLImfIFOusBV8q8VVps4lFQBbNoJK3UpQQa8ixQmGORfB%2BWMH0rbYQLBak4Gwzh35mez%2FKKOwaVheh7zB31C5Aixb564%2B2GBSpyeEpNymJcQA5St%2BJfe1UaNjN3teNzAjINAkOYUDRsBfnx2UAtvXtDZJKlTGDriBpXnGAAcaGryyF4QQzt1vOzUMsR4Db%2BzWOTgjTBWmdFK9DS%2FAholYvk2us1Ub3Gsv6d1aTcWraLjsnQe6apDGwHOnzDcdOiO7aZ0DdKOMnE1FwtWSr1V1k8M3X8Don2cEkn6p2J3MntpPsG9r%2BuA%2FCuATJKMtvDgEq1oQ%3D%3D&X-Amz-Credential=ASIAWUI46DZFFFQZCLPJ%2F20200214%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=3e4ccfb782206018f9490e36e47f18b0877a7b6af18b7c4146e135b60d15056c\n",
            "Resolving binstar-cio-packages-prod.s3.amazonaws.com (binstar-cio-packages-prod.s3.amazonaws.com)... 52.216.109.27\n",
            "Connecting to binstar-cio-packages-prod.s3.amazonaws.com (binstar-cio-packages-prod.s3.amazonaws.com)|52.216.109.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25115678 (24M) [application/x-tar]\n",
            "Saving to: ‘faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2’\n",
            "\n",
            "faiss-gpu-1.2.1-py3 100%[===================>]  23.95M  20.2MB/s    in 1.2s    \n",
            "\n",
            "2020-02-14 09:38:24 (20.2 MB/s) - ‘faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2’ saved [25115678/25115678]\n",
            "\n",
            "info/hash_input.json\n",
            "info/has_prefix\n",
            "info/index.json\n",
            "info/files\n",
            "info/LICENSE.txt\n",
            "info/about.json\n",
            "info/paths.json\n",
            "info/git\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/dependency_links.txt\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/not-zip-safe\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/requires.txt\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/top_level.txt\n",
            "info/test/run_test.py\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/native_libs.txt\n",
            "info/test/run_test.sh\n",
            "info/test/tests/run_tests.sh\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/SOURCES.txt\n",
            "info/recipe/conda_build_config.yaml\n",
            "info/recipe/build.sh\n",
            "info/test/tests/CMakeLists.txt\n",
            "info/test/tests/Makefile\n",
            "info/recipe/meta.yaml.template\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/PKG-INFO\n",
            "info/test/tests/test_factory.py\n",
            "info/test/tests/test_ivfpq_codec.cpp\n",
            "info/recipe/meta.yaml\n",
            "info/recipe/setup.py\n",
            "info/test/tests/test_blas.cpp\n",
            "info/recipe/makefile.inc\n",
            "info/test/tests/test_ivfpq_indexing.cpp\n",
            "info/test/tests/test_ondisk_ivf.cpp\n",
            "info/test/tests/test_build_blocks.py\n",
            "info/test/tests/test_merge.cpp\n",
            "info/test/tests/test_pairs_decoding.cpp\n",
            "info/test/tests/test_index_composite.py\n",
            "lib/python3.6/site-packages/faiss/__init__.py\n",
            "lib/python3.6/site-packages/faiss/__pycache__/__init__.cpython-36.pyc\n",
            "info/test/tests/test_index.py\n",
            "info/test/tests/test_blas\n",
            "lib/python3.6/site-packages/faiss/__pycache__/swigfaiss.cpython-36.pyc\n",
            "lib/python3.6/site-packages/faiss/swigfaiss.py\n",
            "lib/python3.6/site-packages/faiss/__pycache__/swigfaiss_gpu.cpython-36.pyc\n",
            "lib/python3.6/site-packages/faiss/swigfaiss_gpu.py\n",
            "lib/python3.6/site-packages/faiss/_swigfaiss.so\n",
            "lib/python3.6/site-packages/faiss/_swigfaiss_gpu.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3DtEvfctI-N",
        "colab_type": "code",
        "outputId": "7fc2d018-03d7-4711-bfe0-8afdf2dfd0b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!cp -r lib/python3.6/site-packages/* /usr/local/lib/python3.6/dist-packages/\n",
        "!pip install mkl"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mkl in /usr/local/lib/python3.6/dist-packages (2019.0)\n",
            "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.6/dist-packages (from mkl) (2020.0.133)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urrR0nk4tKpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import faiss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3EHRXdFzYFY",
        "colab_type": "text"
      },
      "source": [
        "Now time for downloading datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr7fEPWgzbC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import joblib\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import models, losses\n",
        "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "from sentence_transformers.readers import *\n",
        "from sentence_transformers.util import batch_to_device\n",
        "from sentence_transformers.readers.InputExample import InputExample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClwcM3Wv0J68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
        "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "                    level=logging.INFO,\n",
        "                    handlers=[LoggingHandler()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST-94rcOAHMf",
        "colab_type": "text"
      },
      "source": [
        "# Tatoeba manipulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsb47LBRAGdP",
        "colab_type": "code",
        "outputId": "ac670439-9c74-4216-cba3-003222549450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "!wget https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/moses/de-ru.txt.zip\n",
        "!unzip de-ru.txt.zip -d ./tatoeba/"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-14 09:38:37--  https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/moses/de-ru.txt.zip\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3873926 (3.7M) [application/zip]\n",
            "Saving to: ‘de-ru.txt.zip’\n",
            "\n",
            "\rde-ru.txt.zip         0%[                    ]       0  --.-KB/s               \rde-ru.txt.zip        35%[======>             ]   1.30M  6.07MB/s               \rde-ru.txt.zip       100%[===================>]   3.69M  14.6MB/s    in 0.3s    \n",
            "\n",
            "2020-02-14 09:38:38 (14.6 MB/s) - ‘de-ru.txt.zip’ saved [3873926/3873926]\n",
            "\n",
            "Archive:  de-ru.txt.zip\n",
            "  inflating: ./tatoeba/README        \n",
            "  inflating: ./tatoeba/LICENSE       \n",
            "  inflating: ./tatoeba/Tatoeba.de-ru.de  \n",
            "  inflating: ./tatoeba/Tatoeba.de-ru.ru  \n",
            "  inflating: ./tatoeba/Tatoeba.de-ru.xml  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTCVsnwDViT4",
        "colab_type": "code",
        "outputId": "b2438022-e300-4bc2-f67f-ab36bb573a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "!wget https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/moses/de-en.txt.zip\n",
        "!unzip de-en.txt.zip -d ./tatoeba/\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-14 09:38:41--  https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/moses/de-en.txt.zip\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9957647 (9.5M) [application/zip]\n",
            "Saving to: ‘de-en.txt.zip’\n",
            "\n",
            "de-en.txt.zip       100%[===================>]   9.50M  29.3MB/s    in 0.3s    \n",
            "\n",
            "2020-02-14 09:38:41 (29.3 MB/s) - ‘de-en.txt.zip’ saved [9957647/9957647]\n",
            "\n",
            "Archive:  de-en.txt.zip\n",
            "replace ./tatoeba/README? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ./tatoeba/README        \n",
            "replace ./tatoeba/LICENSE? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ./tatoeba/LICENSE       \n",
            "  inflating: ./tatoeba/Tatoeba.de-en.de  \n",
            "  inflating: ./tatoeba/Tatoeba.de-en.en  \n",
            "  inflating: ./tatoeba/Tatoeba.de-en.xml  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtDnX4LBHZuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TatoebaReader:\n",
        "    \"\"\"Reads in a plain text file, in which every line contains one \n",
        "    sentence.\"\"\"\n",
        "    def __init__(self, file_path: Path):\n",
        "        self.file_path = file_path\n",
        "\n",
        "    def get_examples(self, limit = 5000):\n",
        "        examples = []        \n",
        "        with open(self.file_path) as fin:\n",
        "            for i, line in enumerate(fin.readlines()):\n",
        "                examples.append(InputExample(guid=i, texts=[line], label=0))\n",
        "                if limit == -1 :\n",
        "                  continue\n",
        "                elif i > limit:\n",
        "                  break                \n",
        "        return examples\n",
        "\n",
        "TATOEBA_PATH = Path(\"./tatoeba/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAbTtK8eIFGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Use BERT for mapping tokens to embeddings\n",
        "# handle the downloading and caching for you:\n",
        "word_embedding_model = models.BERT('bert-base-multilingual-cased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufn3Vj2z0nMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def children(m):\n",
        "    return m if isinstance(m, (list, tuple)) else list(m.children())\n",
        "\n",
        "\n",
        "def set_trainable_attr(m, b):\n",
        "    m.trainable = b\n",
        "    for p in m.parameters():\n",
        "        p.requires_grad = b\n",
        "\n",
        "\n",
        "def apply_leaf(m, f):\n",
        "    c = children(m)\n",
        "    if isinstance(m, nn.Module):\n",
        "        f(m)\n",
        "    if len(c) > 0:\n",
        "        for l in c:\n",
        "            apply_leaf(l, f)\n",
        "\n",
        "\n",
        "def set_trainable(l, b):\n",
        "    apply_leaf(l, lambda m: set_trainable_attr(m, b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0xTcgg2IwAq",
        "colab_type": "code",
        "outputId": "5ec648a3-601b-4297-e3be-2ecc7c8a20f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "set_trainable(word_embedding_model.bert.embeddings.word_embeddings, False)\n",
        "print(word_embedding_model.bert.embeddings.word_embeddings.weight.requires_grad)\n",
        "print(word_embedding_model.bert.embeddings.position_embeddings.weight.requires_grad)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvWi2kF-IwYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Apply mean pooling to get one fixed sized sentence vector\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=True,\n",
        "                               pooling_mode_cls_token=False,\n",
        "                               pooling_mode_max_tokens=False)\n",
        "\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STQcxNEv8psK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "TATOEBA_PATH = '/content/tatoeba'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfQVC-hD-uP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lang_1 = 'ru'\n",
        "lang_2 = 'de'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAztWN2HVUQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def evaluate_language_pair(model, pair_name=\"de-en\", batch_size=32):\n",
        "    lang_1, lang_2 = pair_name.split(\"-\")\n",
        "    reader_1 = TatoebaReader(os.path.join(TATOEBA_PATH, f\"Tatoeba.{pair_name}.{lang_1}\"))\n",
        "    ds_1 = SentencesDataset(reader_1.get_examples(), model=model)\n",
        "    loader_1 = DataLoader(\n",
        "        ds_1, shuffle=False, batch_size=batch_size, \n",
        "        collate_fn=model.smart_batching_collate)\n",
        "    reader_2 = TatoebaReader(os.path.join(TATOEBA_PATH, f\"Tatoeba.{pair_name}.{lang_2}\"))    \n",
        "    ds_2 = SentencesDataset(reader_2.get_examples(), model=model)\n",
        "    loader_2 = DataLoader(\n",
        "        ds_2, shuffle=False, batch_size=batch_size, \n",
        "        collate_fn=model.smart_batching_collate)\n",
        "    \n",
        "    model.eval()\n",
        "    emb_1, emb_2 = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader_1:\n",
        "            emb_1.append(model(\n",
        "                batch_to_device(batch, \"cuda\")[0][0]\n",
        "            )['sentence_embedding'])\n",
        "        for batch in loader_2:\n",
        "            emb_2.append(model(\n",
        "                batch_to_device(batch, \"cuda\")[0][0]\n",
        "            )['sentence_embedding'])\n",
        "    emb_1 = torch.cat(emb_1).cpu().numpy()\n",
        "    emb_2 = torch.cat(emb_2).cpu().numpy()\n",
        "    \n",
        "    idx_1 = faiss.IndexFlatL2(emb_1.shape[1])\n",
        "    faiss.normalize_L2(emb_1)\n",
        "    idx_1.add(emb_1)\n",
        "    idx_2 = faiss.IndexFlatL2(emb_2.shape[1])\n",
        "    faiss.normalize_L2(emb_2)\n",
        "    idx_2.add(emb_2)\n",
        "    \n",
        "    results = []\n",
        "    _, match = idx_2.search(x=emb_1, k=1)\n",
        "    results.append((\n",
        "        lang_1, lang_2,\n",
        "        np.sum(match[:, 0] == np.arange(len(emb_1))),\n",
        "        len(emb_1)\n",
        "    ))\n",
        "    _, match = idx_1.search(x=emb_2, k=1)\n",
        "    results.append((\n",
        "        lang_2, lang_1,\n",
        "        np.sum(match[:, 0] == np.arange(len(emb_2))),\n",
        "        len(emb_2)\n",
        "    ))\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3vIWGciW7s1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PAIRS = [\"de-en\", \"de-ru\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vfuPWfFW2_r",
        "colab_type": "code",
        "outputId": "f12b0f6c-8e31-4e70-998f-2d789b7956bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "results = []\n",
        "for pair in PAIRS:\n",
        "    results += evaluate_language_pair(model, pair_name=pair, batch_size=50)\n",
        "df_baseline_mean = pd.DataFrame(results, columns=[\"from\", \"to\", \"correct\", \"total\"])\n",
        "df_baseline_mean"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>correct</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>de</td>\n",
              "      <td>en</td>\n",
              "      <td>1009</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "      <td>960</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>de</td>\n",
              "      <td>ru</td>\n",
              "      <td>982</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ru</td>\n",
              "      <td>de</td>\n",
              "      <td>1005</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  from  to  correct  total\n",
              "0   de  en     1009   5002\n",
              "1   en  de      960   5002\n",
              "2   de  ru      982   5002\n",
              "3   ru  de     1005   5002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05QAe_VEhfDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5c152c9f-b144-4a6e-df54-e784f64728f6"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YKF7i23_wvX",
        "colab_type": "text"
      },
      "source": [
        "# Fine Tuning \n",
        "\n",
        "Firstly, just download datasets for fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Wluv9mz13w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "folder_path = './datasets/'\n",
        "\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJhAf6CstNKN",
        "colab_type": "code",
        "outputId": "499da7f4-f395-4314-ff67-a9afca5d788b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "print('Beginning download of datasets')\n",
        "\n",
        "datasets = ['AllNLI.zip', 'stsbenchmark.zip', 'wikipedia-sections-triplets.zip']\n",
        "server = \"https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/datasets/\"\n",
        "\n",
        "for dataset in datasets:\n",
        "    print(\"Download\", dataset)\n",
        "    url = server+dataset\n",
        "    dataset_path = os.path.join(folder_path, dataset)\n",
        "    urllib.request.urlretrieve(url, dataset_path)\n",
        "\n",
        "    print(\"Extract\", dataset)\n",
        "    with zipfile.ZipFile(dataset_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(folder_path)\n",
        "    os.remove(dataset_path)\n",
        "\n",
        "\n",
        "print(\"All datasets downloaded and extracted\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning download of datasets\n",
            "Download AllNLI.zip\n",
            "Extract AllNLI.zip\n",
            "Download stsbenchmark.zip\n",
            "Extract stsbenchmark.zip\n",
            "Download wikipedia-sections-triplets.zip\n",
            "Extract wikipedia-sections-triplets.zip\n",
            "All datasets downloaded and extracted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBxfuTrd0VZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Read the dataset\n",
        "batch_size = 16\n",
        "nli_reader = NLIDataReader('./datasets/AllNLI')\n",
        "sts_reader = STSDataReader('./datasets/stsbenchmark')\n",
        "train_num_labels = nli_reader.get_num_labels()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8pn1cun00fR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the dataset to a DataLoader ready for training\n",
        "logging.info(\"Read AllNLI train dataset\")\n",
        "train_data = SentencesDataset(nli_reader.get_examples('train.gz', max_examples=100000), model=model)\n",
        "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "train_loss = losses.SoftmaxLoss(\n",
        "    model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=train_num_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M71gPAon1E6p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "eb4267d0-180e-450f-fc5c-f5e95ef1ce84"
      },
      "source": [
        "joblib.dump(train_data, \"allnli_train_dataset.jl\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['allnli_train_dataset.jl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GXgDNQY1BEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "logging.info(\"Read STSbenchmark dev dataset\")\n",
        "dev_data = SentencesDataset(examples=sts_reader.get_examples('sts-dev.csv'), model=model)\n",
        "dev_dataloader = DataLoader(dev_data, shuffle=False, batch_size=batch_size)\n",
        "evaluator = EmbeddingSimilarityEvaluator(dev_dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbAsVlmC1Ifu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d04764bf-1206-4999-fb42-2b2f9d793f33"
      },
      "source": [
        "joblib.dump(dev_data, \"sts_dev_dataset.jl\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sts_dev_dataset.jl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYki766lfOar",
        "colab_type": "code",
        "outputId": "d4010247-2517-453d-8e0a-ca9d1fdf4124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaoTrJ829-Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checkpoint_path = \"gdrive/embeddings_01/cp.ckpt\"\n",
        "#checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create checkpoint callback\n",
        "#cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
        "#                                                 save_weights_only=True,\n",
        "#                                                 verbose=1)\n",
        "model_save_path = 'drive/My Drive/models/training_nli_bert-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J_XLV109bOd",
        "colab_type": "text"
      },
      "source": [
        "### PAUSE HERE!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBG5I8Uh1Nc5",
        "colab_type": "code",
        "outputId": "53587bc0-7563-4e4c-bfa4-56a4d10bcdc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# Configure the training\n",
        "num_epochs = 1\n",
        "\n",
        "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
        "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
        "          evaluator=evaluator,\n",
        "          epochs=num_epochs,\n",
        "          evaluation_steps=1000,\n",
        "          warmup_steps=warmup_steps,\n",
        "          output_path=model_save_path\n",
        "          )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9c5970de474a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwarmup_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#10% of train data for warm-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Warmup-steps: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ174o5CqLlw",
        "colab_type": "text"
      },
      "source": [
        "# After fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1N_eHMC_hhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jbCZKrn3tkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = SentenceTransformer('/content/output/training_nli_bert-2020-01-13_14-53-24')\n",
        "#model = SentenceTransformer('/content/output/training_nli_bert-2020-01-23_17-06-00')\n",
        "#model = SentenceTransformer('/content/gdrive/output/training_nli_bert-2020-02-09_11-48-02')\n",
        "model = SentenceTransformer('/content/drive/My Drive/models/training_nli_bert-2020-02-09_13-04-35')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfvOkkbwrUj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []\n",
        "for pair in PAIRS:\n",
        "    results += evaluate_language_pair(model, pair_name=pair, batch_size=50)\n",
        "df_finetuned = pd.DataFrame(results, columns=[\"from\", \"to\", \"correct\", \"total\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f9ZEcAQrbO0",
        "colab_type": "code",
        "outputId": "5eb2e4d6-8d6a-4bbb-eb46-df12a3e42379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "df_finetuned"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>correct</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>de</td>\n",
              "      <td>en</td>\n",
              "      <td>651</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "      <td>660</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>de</td>\n",
              "      <td>ru</td>\n",
              "      <td>747</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ru</td>\n",
              "      <td>de</td>\n",
              "      <td>742</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  from  to  correct  total\n",
              "0   de  en      651   5002\n",
              "1   en  de      660   5002\n",
              "2   de  ru      747   5002\n",
              "3   ru  de      742   5002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pirQqWKjruUU",
        "colab_type": "code",
        "outputId": "51189751-96d9-4f2f-e5d1-70b1af0a4834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "df_baseline_mean"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>correct</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>de</td>\n",
              "      <td>en</td>\n",
              "      <td>1009</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "      <td>960</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>de</td>\n",
              "      <td>ru</td>\n",
              "      <td>982</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ru</td>\n",
              "      <td>de</td>\n",
              "      <td>1005</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  from  to  correct  total\n",
              "0   de  en     1009   5002\n",
              "1   en  de      960   5002\n",
              "2   de  ru      982   5002\n",
              "3   ru  de     1005   5002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgIUK7aury2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embedding_model = models.BERT('bert-base-multilingual-cased')\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=False,\n",
        "                               pooling_mode_cls_token=True,\n",
        "                               pooling_mode_max_tokens=False)\n",
        "\n",
        "model_cls = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbmeP7ooto49",
        "colab_type": "code",
        "outputId": "e0c546f2-d507-42d8-f312-a093cb9c37f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "results = []\n",
        "for pair in PAIRS:\n",
        "    results += evaluate_language_pair(model_cls, pair_name=pair, batch_size=50)\n",
        "df_baseline_cls = pd.DataFrame(results, columns=[\"from\", \"to\", \"correct\", \"total\"])\n",
        "df_baseline_cls"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>correct</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>de</td>\n",
              "      <td>en</td>\n",
              "      <td>196</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "      <td>476</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>de</td>\n",
              "      <td>ru</td>\n",
              "      <td>402</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ru</td>\n",
              "      <td>de</td>\n",
              "      <td>542</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  from  to  correct  total\n",
              "0   de  en      196   5002\n",
              "1   en  de      476   5002\n",
              "2   de  ru      402   5002\n",
              "3   ru  de      542   5002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THX7EAm9tvoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embedding_model = models.BERT('bert-base-multilingual-cased')\n",
        "# Apply mean pooling to get one fixed sized sentence vector\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=False,\n",
        "                               pooling_mode_cls_token=False,\n",
        "                               pooling_mode_max_tokens=True)\n",
        "model_max = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO5labgOuah9",
        "colab_type": "code",
        "outputId": "700d8df9-1cc0-4353-8167-e9a3a0689320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "results = []\n",
        "for pair in PAIRS:\n",
        "    results += evaluate_language_pair(model_max, pair_name=pair, batch_size=50)\n",
        "df_baseline_max = pd.DataFrame(results, columns=[\"from\", \"to\", \"correct\", \"total\"])\n",
        "df_baseline_max"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>correct</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>de</td>\n",
              "      <td>en</td>\n",
              "      <td>317</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "      <td>765</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>de</td>\n",
              "      <td>ru</td>\n",
              "      <td>684</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ru</td>\n",
              "      <td>de</td>\n",
              "      <td>619</td>\n",
              "      <td>5002</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  from  to  correct  total\n",
              "0   de  en      317   5002\n",
              "1   en  de      765   5002\n",
              "2   de  ru      684   5002\n",
              "3   ru  de      619   5002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz6InpLOusVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_baseline_mean[\"err_mean\"] = 1 - df_baseline_mean[\"correct\"] / df_baseline_mean[\"total\"]\n",
        "df_baseline_max[\"err_max\"] = 1 - df_baseline_max[\"correct\"] / df_baseline_max[\"total\"]\n",
        "df_baseline_cls[\"err_cls\"] = 1 - df_baseline_cls[\"correct\"] / df_baseline_cls[\"total\"]\n",
        "df_finetuned[\"err_finetuned\"] = 1 - df_finetuned[\"correct\"] / df_finetuned[\"total\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yep9v95ivngh",
        "colab_type": "code",
        "outputId": "ce3bc8e7-cfe6-4dab-e5c5-08f98d3f3c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "df_err = pd.concat([\n",
        "    df.set_index([\"from\", \"to\"]).drop([\"correct\", \"total\"], axis=1)\n",
        "    for df in (df_baseline_mean, df_baseline_max, df_baseline_cls, df_finetuned)\n",
        "], axis=1)\n",
        "df_err"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>err_mean</th>\n",
              "      <th>err_max</th>\n",
              "      <th>err_cls</th>\n",
              "      <th>err_finetuned</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>de</th>\n",
              "      <th>en</th>\n",
              "      <td>0.798281</td>\n",
              "      <td>0.936625</td>\n",
              "      <td>0.960816</td>\n",
              "      <td>0.869852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>en</th>\n",
              "      <th>de</th>\n",
              "      <td>0.808077</td>\n",
              "      <td>0.847061</td>\n",
              "      <td>0.904838</td>\n",
              "      <td>0.868053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>de</th>\n",
              "      <th>ru</th>\n",
              "      <td>0.803679</td>\n",
              "      <td>0.863255</td>\n",
              "      <td>0.919632</td>\n",
              "      <td>0.850660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ru</th>\n",
              "      <th>de</th>\n",
              "      <td>0.799080</td>\n",
              "      <td>0.876250</td>\n",
              "      <td>0.891643</td>\n",
              "      <td>0.851659</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         err_mean   err_max   err_cls  err_finetuned\n",
              "from to                                             \n",
              "de   en  0.798281  0.936625  0.960816       0.869852\n",
              "en   de  0.808077  0.847061  0.904838       0.868053\n",
              "de   ru  0.803679  0.863255  0.919632       0.850660\n",
              "ru   de  0.799080  0.876250  0.891643       0.851659"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    }
  ]
}