{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentence-embeddings.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alinaalborova/sentence-transformers/blob/master/sentence_embeddings_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLeV1Uy2-itV",
        "colab_type": "code",
        "outputId": "944b68eb-632b-4fca-86be-006429df48ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: sentence-transformers in /usr/local/lib/python3.6/dist-packages (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: transformers==2.3.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (0.1.85)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (1.11.10)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (0.0.38)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (0.3.2)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (0.9.4)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.15.0,>=1.14.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (1.14.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0->sentence-transformers) (7.0)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers==2.3.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers==2.3.0->sentence-transformers) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_73o_OhV4lQy",
        "colab_type": "code",
        "outputId": "6f97f188-cff2-4247-e6cf-099da865a814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!pip install h5py pyyaml"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73ps5AR44n4t",
        "colab_type": "code",
        "outputId": "074d6615-5280-48e0-c42c-86286d74da16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT4xn5PD_B4_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "f09a15e3-f1c8-4c4e-8591-ecac0ddacc0f"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c4e037d073ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-nli-mean-tokens'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device)\u001b[0m\n\u001b[1;32m     74\u001b[0m                             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You try to use a model that was created with version {}, however, your version is {}. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\\n\\n\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__version__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'modules.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfIn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                     \u001b[0mcontained_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfIn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip/modules.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1MJnL5W_JKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "b325989f-437e-4813-e33f-ce5146a2539e"
      },
      "source": [
        "sentences = ['This framework generates embeddings for each input sentence',\n",
        "    'Sentences are passed as a list of string.', \n",
        "    'The quick brown fox jumps over the lazy dog.']\n",
        "sentence_embeddings = model.encode(sentences)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-03bb672e7305>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m'Sentences are passed as a list of string.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     'The quick brown fox jumps over the lazy dog.']\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msentence_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BERT' object has no attribute 'encode'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3RT3x-f_Pvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sentence, embedding in zip(sentences, sentence_embeddings):\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding:\", len(embedding), embedding[:10])\n",
        "    print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsXovfJm_SFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_embeddings = model.encode(['Мама мыла раму'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VjfgQmt_b6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rus_sentences = ['мама мыла раму', 'рама мыла маму']\n",
        "rus_sentences_embeddings = model.encode(rus_sentences)\n",
        "for sentence, embedding in zip(rus_sentences, rus_sentences_embeddings):\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding:\", len(embedding), embedding[:10])\n",
        "    print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oILRpQJK_s-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "de_sentences = ['Mein Hund ist gross', 'Meine Katze ist gross', 'Mein Hund ist klein', 'Dein Hund ist klein', 'Dein Hund ist gross', 'Meine Katze ist klein', 'Deine Katze ist klein', 'Deine Katze ist gross']\n",
        "de_sentences_embeddings = model.encode(de_sentences)\n",
        "for sentence, embedding in zip(de_sentences, de_sentences_embeddings):\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding:\", len(embedding), embedding[:10])\n",
        "    print(\"\")    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5-RxFX6tCra",
        "colab_type": "text"
      },
      "source": [
        "# FAISS Installation\n",
        "\n",
        "Sadly, it can be painfull :(\n",
        "\n",
        "In according to answer from SO: https://stackoverflow.com/questions/47967252/installing-faiss-on-google-colaboratory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWJMV4xZAFXV",
        "colab_type": "code",
        "outputId": "be7d130f-c53f-4999-9888-ddde295b3811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#!wget  https://anaconda.org/pytorch/faiss-cpu/1.2.1/download/linux-64/faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "#!tar xvjf faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "!wget https://anaconda.org/pytorch/faiss-gpu/1.2.1/download/linux-64/faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "!tar xvjf faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-13 13:06:10--  https://anaconda.org/pytorch/faiss-gpu/1.2.1/download/linux-64/faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
            "Resolving anaconda.org (anaconda.org)... 104.17.93.24, 104.17.92.24, 2606:4700::6811:5d18, ...\n",
            "Connecting to anaconda.org (anaconda.org)|104.17.93.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://binstar-cio-packages-prod.s3.amazonaws.com/5a15c9cc393ec612061f033a/5ac54beae586bb11ec0ace46?response-content-disposition=attachment%3B%20filename%3D%22faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2%22%3B%20filename%2A%3DUTF-8%27%27faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2&response-content-type=application%2Fx-tar&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=60&X-Amz-Date=20200213T130611Z&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEKT%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCICwQkNzsG37VNuZKlZNT0dwNKgCGwxiRITKMkIuySDXsAiEAyM1V8UVxPrarHJpZnJPTvfB9ne%2Bl4hQipW7be7%2F3p0wqtAMIXBAAGgw0NTU4NjQwOTgzNzgiDNNBz5q5h%2FSvRHJ5SSqRA7FaXxB1u%2FMGp9oKY71g1binC0q%2FzIfgVMzXOMAh3OsxRtwRvhFgYTwO3gngseGy%2BMYS0cabxBy5zihn1XmO438yXrp1dC53uU1RawfmrCPJpQh2DGm8Iq8e9cDNfDAYDqZS6un15cyaTlDlO3AADFL%2F4mZhhZ3QJvMcT0CXQgyWnxEBxQa7Kl1Wkzv7y5I8CM47NpfSw1dOW6wkIwLSv9f0sDOxJU%2FjzfeqrO2huuB8Jm1E45ZHIxqT%2Bx4C4mQsEhggUmBDZCS22JKS8VnMzYDV8cS57xNqODVB5qInXZY5%2BrkEC2%2FtMXUp%2FAjQ0J3K00sreE50eD6ylXfBOdMNYi412qvK%2FvsevYuElQEJOjnFUydgxupqafyn72G4K9ziRYcoIo8RPmuISbKVU4OYNbsyZqEW%2BxqRb2xo4cBEBVSPqJWB613hsybprU7qIK19VHb8vCEwMKo1pyomfQOJKOnK0aL6ZaxLcJWl5OFvYXa5JhH42RqH9ryRrwDvuzfUJxX1YNa3ltBeTi3ILowXEFPvMKLhlPIFOusBYc0nQkdNnh%2BU81cvcVlZfjoZI%2FLFtzkHlefx%2BbJrAB%2FvOdzf352RvJrZm9NKS%2FFYD6%2BLJNnnTCbulreNrQaJZbrTQUzZkxb4H8Hl3yYQBHXEvV2n%2FzZ%2FHZRLwYYp1ddlbxULdzMcv0w2SmLL3IplX5U%2Bu%2B3uBzVYwF9yprbVgcOBsNlKfxIP9RgWHDXhJhzw1htFE5XzpK5%2BoHJl27pxY5pEgU3UBEL%2FOU5ah3E0%2FF79hfD8%2FyBMfr1KtVmB2NKHYqCMzMoT2NsilLjx%2B5xUIRreW0wCfFo5ZNI4KegovCxqxMCHzmXzNwtaEQ%3D%3D&X-Amz-Credential=ASIAWUI46DZFK7FUHBXP%2F20200213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=ed160c63fe6f0cdcf7e72ae9a9749da44b3cf245af5565a59ed4ec4c0ff603d8 [following]\n",
            "--2020-02-13 13:06:11--  https://binstar-cio-packages-prod.s3.amazonaws.com/5a15c9cc393ec612061f033a/5ac54beae586bb11ec0ace46?response-content-disposition=attachment%3B%20filename%3D%22faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2%22%3B%20filename%2A%3DUTF-8%27%27faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2&response-content-type=application%2Fx-tar&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=60&X-Amz-Date=20200213T130611Z&X-Amz-SignedHeaders=host&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEKT%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCICwQkNzsG37VNuZKlZNT0dwNKgCGwxiRITKMkIuySDXsAiEAyM1V8UVxPrarHJpZnJPTvfB9ne%2Bl4hQipW7be7%2F3p0wqtAMIXBAAGgw0NTU4NjQwOTgzNzgiDNNBz5q5h%2FSvRHJ5SSqRA7FaXxB1u%2FMGp9oKY71g1binC0q%2FzIfgVMzXOMAh3OsxRtwRvhFgYTwO3gngseGy%2BMYS0cabxBy5zihn1XmO438yXrp1dC53uU1RawfmrCPJpQh2DGm8Iq8e9cDNfDAYDqZS6un15cyaTlDlO3AADFL%2F4mZhhZ3QJvMcT0CXQgyWnxEBxQa7Kl1Wkzv7y5I8CM47NpfSw1dOW6wkIwLSv9f0sDOxJU%2FjzfeqrO2huuB8Jm1E45ZHIxqT%2Bx4C4mQsEhggUmBDZCS22JKS8VnMzYDV8cS57xNqODVB5qInXZY5%2BrkEC2%2FtMXUp%2FAjQ0J3K00sreE50eD6ylXfBOdMNYi412qvK%2FvsevYuElQEJOjnFUydgxupqafyn72G4K9ziRYcoIo8RPmuISbKVU4OYNbsyZqEW%2BxqRb2xo4cBEBVSPqJWB613hsybprU7qIK19VHb8vCEwMKo1pyomfQOJKOnK0aL6ZaxLcJWl5OFvYXa5JhH42RqH9ryRrwDvuzfUJxX1YNa3ltBeTi3ILowXEFPvMKLhlPIFOusBYc0nQkdNnh%2BU81cvcVlZfjoZI%2FLFtzkHlefx%2BbJrAB%2FvOdzf352RvJrZm9NKS%2FFYD6%2BLJNnnTCbulreNrQaJZbrTQUzZkxb4H8Hl3yYQBHXEvV2n%2FzZ%2FHZRLwYYp1ddlbxULdzMcv0w2SmLL3IplX5U%2Bu%2B3uBzVYwF9yprbVgcOBsNlKfxIP9RgWHDXhJhzw1htFE5XzpK5%2BoHJl27pxY5pEgU3UBEL%2FOU5ah3E0%2FF79hfD8%2FyBMfr1KtVmB2NKHYqCMzMoT2NsilLjx%2B5xUIRreW0wCfFo5ZNI4KegovCxqxMCHzmXzNwtaEQ%3D%3D&X-Amz-Credential=ASIAWUI46DZFK7FUHBXP%2F20200213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=ed160c63fe6f0cdcf7e72ae9a9749da44b3cf245af5565a59ed4ec4c0ff603d8\n",
            "Resolving binstar-cio-packages-prod.s3.amazonaws.com (binstar-cio-packages-prod.s3.amazonaws.com)... 52.216.8.67\n",
            "Connecting to binstar-cio-packages-prod.s3.amazonaws.com (binstar-cio-packages-prod.s3.amazonaws.com)|52.216.8.67|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25115678 (24M) [application/x-tar]\n",
            "Saving to: ‘faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2’\n",
            "\n",
            "faiss-gpu-1.2.1-py3 100%[===================>]  23.95M  9.09MB/s    in 2.6s    \n",
            "\n",
            "2020-02-13 13:06:14 (9.09 MB/s) - ‘faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2’ saved [25115678/25115678]\n",
            "\n",
            "info/hash_input.json\n",
            "info/has_prefix\n",
            "info/index.json\n",
            "info/files\n",
            "info/LICENSE.txt\n",
            "info/about.json\n",
            "info/paths.json\n",
            "info/git\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/dependency_links.txt\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/not-zip-safe\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/requires.txt\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/top_level.txt\n",
            "info/test/run_test.py\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/native_libs.txt\n",
            "info/test/run_test.sh\n",
            "info/test/tests/run_tests.sh\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/SOURCES.txt\n",
            "info/recipe/conda_build_config.yaml\n",
            "info/recipe/build.sh\n",
            "info/test/tests/CMakeLists.txt\n",
            "info/test/tests/Makefile\n",
            "info/recipe/meta.yaml.template\n",
            "lib/python3.6/site-packages/faiss-0.1-py3.6.egg-info/PKG-INFO\n",
            "info/test/tests/test_factory.py\n",
            "info/test/tests/test_ivfpq_codec.cpp\n",
            "info/recipe/meta.yaml\n",
            "info/recipe/setup.py\n",
            "info/test/tests/test_blas.cpp\n",
            "info/recipe/makefile.inc\n",
            "info/test/tests/test_ivfpq_indexing.cpp\n",
            "info/test/tests/test_ondisk_ivf.cpp\n",
            "info/test/tests/test_build_blocks.py\n",
            "info/test/tests/test_merge.cpp\n",
            "info/test/tests/test_pairs_decoding.cpp\n",
            "info/test/tests/test_index_composite.py\n",
            "lib/python3.6/site-packages/faiss/__init__.py\n",
            "lib/python3.6/site-packages/faiss/__pycache__/__init__.cpython-36.pyc\n",
            "info/test/tests/test_index.py\n",
            "info/test/tests/test_blas\n",
            "lib/python3.6/site-packages/faiss/__pycache__/swigfaiss.cpython-36.pyc\n",
            "lib/python3.6/site-packages/faiss/swigfaiss.py\n",
            "lib/python3.6/site-packages/faiss/__pycache__/swigfaiss_gpu.cpython-36.pyc\n",
            "lib/python3.6/site-packages/faiss/swigfaiss_gpu.py\n",
            "lib/python3.6/site-packages/faiss/_swigfaiss.so\n",
            "lib/python3.6/site-packages/faiss/_swigfaiss_gpu.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3DtEvfctI-N",
        "colab_type": "code",
        "outputId": "43218ec7-795d-472a-f991-91d77906eb8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!cp -r lib/python3.6/site-packages/* /usr/local/lib/python3.6/dist-packages/\n",
        "!pip install mkl"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mkl in /usr/local/lib/python3.6/dist-packages (2019.0)\n",
            "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.6/dist-packages (from mkl) (2020.0.133)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urrR0nk4tKpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import faiss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3EHRXdFzYFY",
        "colab_type": "text"
      },
      "source": [
        "Now time for downloading datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr7fEPWgzbC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import joblib\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import models, losses\n",
        "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "from sentence_transformers.readers import *\n",
        "from sentence_transformers.util import batch_to_device\n",
        "from sentence_transformers.readers.InputExample import InputExample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClwcM3Wv0J68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
        "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "                    level=logging.INFO,\n",
        "                    handlers=[LoggingHandler()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST-94rcOAHMf",
        "colab_type": "text"
      },
      "source": [
        "# Tatoeba manipulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsb47LBRAGdP",
        "colab_type": "code",
        "outputId": "2efbf78a-a53d-4626-9a91-d4aab598aa22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "!wget https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/moses/de-ru.txt.zip\n",
        "!unzip de-ru.txt.zip -d ./tatoeba/"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-13 13:06:28--  https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/moses/de-ru.txt.zip\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3873926 (3.7M) [application/zip]\n",
            "Saving to: ‘de-ru.txt.zip’\n",
            "\n",
            "de-ru.txt.zip       100%[===================>]   3.69M  1.84MB/s    in 2.0s    \n",
            "\n",
            "2020-02-13 13:06:32 (1.84 MB/s) - ‘de-ru.txt.zip’ saved [3873926/3873926]\n",
            "\n",
            "Archive:  de-ru.txt.zip\n",
            "  inflating: ./tatoeba/README        \n",
            "  inflating: ./tatoeba/LICENSE       \n",
            "  inflating: ./tatoeba/Tatoeba.de-ru.de  \n",
            "  inflating: ./tatoeba/Tatoeba.de-ru.ru  \n",
            "  inflating: ./tatoeba/Tatoeba.de-ru.xml  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTCVsnwDViT4",
        "colab_type": "code",
        "outputId": "c9109611-5ea2-4956-d6c8-80b45162c790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "!wget https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/moses/de-en.txt.zip\n",
        "!unzip de-en.txt.zip -d ./tatoeba/\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-13 13:06:37--  https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/moses/de-en.txt.zip\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9957647 (9.5M) [application/zip]\n",
            "Saving to: ‘de-en.txt.zip’\n",
            "\n",
            "de-en.txt.zip       100%[===================>]   9.50M  3.68MB/s    in 2.6s    \n",
            "\n",
            "2020-02-13 13:06:41 (3.68 MB/s) - ‘de-en.txt.zip’ saved [9957647/9957647]\n",
            "\n",
            "Archive:  de-en.txt.zip\n",
            "replace ./tatoeba/README? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace ./tatoeba/LICENSE? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace ./tatoeba/LICENSE? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "  inflating: ./tatoeba/Tatoeba.de-en.de  \n",
            "  inflating: ./tatoeba/Tatoeba.de-en.en  \n",
            "  inflating: ./tatoeba/Tatoeba.de-en.xml  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtDnX4LBHZuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TatoebaReader:\n",
        "    \"\"\"Reads in a plain text file, in which every line contains one \n",
        "    sentence.\"\"\"\n",
        "    def __init__(self, file_path: Path):\n",
        "        self.file_path = file_path\n",
        "\n",
        "    def get_examples(self, limit = 500):\n",
        "        examples = []        \n",
        "        with open(self.file_path) as fin:\n",
        "            for i, line in enumerate(fin.readlines()):\n",
        "                examples.append(InputExample(guid=i, texts=[line], label=0))\n",
        "                if limit == -1 :\n",
        "                  continue\n",
        "                elif i > limit:\n",
        "                  break                \n",
        "        return examples\n",
        "\n",
        "TATOEBA_PATH = Path(\"./tatoeba/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAbTtK8eIFGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Use BERT for mapping tokens to embeddings\n",
        "# handle the downloading and caching for you:\n",
        "word_embedding_model = models.BERT('bert-base-multilingual-cased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufn3Vj2z0nMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def children(m):\n",
        "    return m if isinstance(m, (list, tuple)) else list(m.children())\n",
        "\n",
        "\n",
        "def set_trainable_attr(m, b):\n",
        "    m.trainable = b\n",
        "    for p in m.parameters():\n",
        "        p.requires_grad = b\n",
        "\n",
        "\n",
        "def apply_leaf(m, f):\n",
        "    c = children(m)\n",
        "    if isinstance(m, nn.Module):\n",
        "        f(m)\n",
        "    if len(c) > 0:\n",
        "        for l in c:\n",
        "            apply_leaf(l, f)\n",
        "\n",
        "\n",
        "def set_trainable(l, b):\n",
        "    apply_leaf(l, lambda m: set_trainable_attr(m, b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0xTcgg2IwAq",
        "colab_type": "code",
        "outputId": "eb1c1109-6a05-469c-84be-d9d24b774950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "set_trainable(word_embedding_model.bert.embeddings.word_embeddings, False)\n",
        "print(word_embedding_model.bert.embeddings.word_embeddings.weight.requires_grad)\n",
        "print(word_embedding_model.bert.embeddings.position_embeddings.weight.requires_grad)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvWi2kF-IwYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Apply mean pooling to get one fixed sized sentence vector\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=True,\n",
        "                               pooling_mode_cls_token=False,\n",
        "                               pooling_mode_max_tokens=False)\n",
        "\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STQcxNEv8psK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "TATOEBA_PATH = '/content/tatoeba'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfQVC-hD-uP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lang_1 = 'ru'\n",
        "lang_2 = 'de'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAztWN2HVUQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def evaluate_language_pair(model, pair_name=\"de-en\", batch_size=32):\n",
        "    lang_1, lang_2 = pair_name.split(\"-\")\n",
        "    reader_1 = TatoebaReader(os.path.join(TATOEBA_PATH, f\"Tatoeba.{pair_name}.{lang_1}\"))\n",
        "    ds_1 = SentencesDataset(reader_1.get_examples(), model=model)\n",
        "    loader_1 = DataLoader(\n",
        "        ds_1, shuffle=False, batch_size=batch_size, \n",
        "        collate_fn=model.smart_batching_collate)\n",
        "    reader_2 = TatoebaReader(os.path.join(TATOEBA_PATH, f\"Tatoeba.{pair_name}.{lang_2}\"))    \n",
        "    ds_2 = SentencesDataset(reader_2.get_examples(), model=model)\n",
        "    loader_2 = DataLoader(\n",
        "        ds_2, shuffle=False, batch_size=batch_size, \n",
        "        collate_fn=model.smart_batching_collate)\n",
        "    \n",
        "    model.eval()\n",
        "    emb_1, emb_2 = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader_1:\n",
        "            emb_1.append(model(\n",
        "                batch_to_device(batch, \"cuda\")[0][0]\n",
        "            )['sentence_embedding'])\n",
        "        for batch in loader_2:\n",
        "            emb_2.append(model(\n",
        "                batch_to_device(batch, \"cuda\")[0][0]\n",
        "            )['sentence_embedding'])\n",
        "    emb_1 = torch.cat(emb_1).cpu().numpy()\n",
        "    emb_2 = torch.cat(emb_2).cpu().numpy()\n",
        "    \n",
        "    idx_1 = faiss.IndexFlatL2(emb_1.shape[1])\n",
        "    faiss.normalize_L2(emb_1)\n",
        "    idx_1.add(emb_1)\n",
        "    idx_2 = faiss.IndexFlatL2(emb_2.shape[1])\n",
        "    faiss.normalize_L2(emb_2)\n",
        "    idx_2.add(emb_2)\n",
        "    \n",
        "    results = []\n",
        "    _, match = idx_2.search(x=emb_1, k=1)\n",
        "    results.append((\n",
        "        lang_1, lang_2,\n",
        "        np.sum(match[:, 0] == np.arange(len(emb_1))),\n",
        "        len(emb_1)\n",
        "    ))\n",
        "    _, match = idx_1.search(x=emb_2, k=1)\n",
        "    results.append((\n",
        "        lang_2, lang_1,\n",
        "        np.sum(match[:, 0] == np.arange(len(emb_2))),\n",
        "        len(emb_2)\n",
        "    ))\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3vIWGciW7s1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PAIRS = [\"de-en\", \"de-ru\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vfuPWfFW2_r",
        "colab_type": "code",
        "outputId": "5a6861f1-90cd-4fac-9121-b550e75af1cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "results = []\n",
        "for pair in PAIRS:\n",
        "    results += evaluate_language_pair(model, pair_name=pair, batch_size=50)\n",
        "df_baseline_mean = pd.DataFrame(results, columns=[\"from\", \"to\", \"correct\", \"total\"])\n",
        "df_baseline_mean"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>correct</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>de</td>\n",
              "      <td>en</td>\n",
              "      <td>210</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "      <td>194</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>de</td>\n",
              "      <td>ru</td>\n",
              "      <td>200</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ru</td>\n",
              "      <td>de</td>\n",
              "      <td>184</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  from  to  correct  total\n",
              "0   de  en      210    502\n",
              "1   en  de      194    502\n",
              "2   de  ru      200    502\n",
              "3   ru  de      184    502"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05QAe_VEhfDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YKF7i23_wvX",
        "colab_type": "text"
      },
      "source": [
        "# Fine Tuning \n",
        "\n",
        "Firstly, just download datasets for fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Wluv9mz13w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "folder_path = './datasets/'\n",
        "\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJhAf6CstNKN",
        "colab_type": "code",
        "outputId": "060b4a2e-c12d-4d3a-b5bc-43dfa8be9eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "print('Beginning download of datasets')\n",
        "\n",
        "datasets = ['AllNLI.zip', 'stsbenchmark.zip', 'wikipedia-sections-triplets.zip']\n",
        "server = \"https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/datasets/\"\n",
        "\n",
        "for dataset in datasets:\n",
        "    print(\"Download\", dataset)\n",
        "    url = server+dataset\n",
        "    dataset_path = os.path.join(folder_path, dataset)\n",
        "    urllib.request.urlretrieve(url, dataset_path)\n",
        "\n",
        "    print(\"Extract\", dataset)\n",
        "    with zipfile.ZipFile(dataset_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(folder_path)\n",
        "    os.remove(dataset_path)\n",
        "\n",
        "\n",
        "print(\"All datasets downloaded and extracted\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning download of datasets\n",
            "Download AllNLI.zip\n",
            "Extract AllNLI.zip\n",
            "Download stsbenchmark.zip\n",
            "Extract stsbenchmark.zip\n",
            "Download wikipedia-sections-triplets.zip\n",
            "Extract wikipedia-sections-triplets.zip\n",
            "All datasets downloaded and extracted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBxfuTrd0VZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Read the dataset\n",
        "batch_size = 16\n",
        "nli_reader = NLIDataReader('./datasets/AllNLI')\n",
        "sts_reader = STSDataReader('./datasets/stsbenchmark')\n",
        "train_num_labels = nli_reader.get_num_labels()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8pn1cun00fR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the dataset to a DataLoader ready for training\n",
        "logging.info(\"Read AllNLI train dataset\")\n",
        "train_data = SentencesDataset(nli_reader.get_examples('train.gz', max_examples=100000), model=model)\n",
        "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "train_loss = losses.SoftmaxLoss(\n",
        "    model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=train_num_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M71gPAon1E6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "joblib.dump(train_data, \"allnli_train_dataset.jl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GXgDNQY1BEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "logging.info(\"Read STSbenchmark dev dataset\")\n",
        "dev_data = SentencesDataset(examples=sts_reader.get_examples('sts-dev.csv'), model=model)\n",
        "dev_dataloader = DataLoader(dev_data, shuffle=False, batch_size=batch_size)\n",
        "evaluator = EmbeddingSimilarityEvaluator(dev_dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbAsVlmC1Ifu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "joblib.dump(dev_data, \"sts_dev_dataset.jl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYki766lfOar",
        "colab_type": "code",
        "outputId": "36dc8b5c-0829-482a-a8d1-62fe5015c2eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaoTrJ829-Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checkpoint_path = \"gdrive/embeddings_01/cp.ckpt\"\n",
        "#checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create checkpoint callback\n",
        "#cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
        "#                                                 save_weights_only=True,\n",
        "#                                                 verbose=1)\n",
        "model_save_path = 'drive/My Drive/models/training_nli_bert-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J_XLV109bOd",
        "colab_type": "text"
      },
      "source": [
        "### PAUSE HERE!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBG5I8Uh1Nc5",
        "colab_type": "code",
        "outputId": "53587bc0-7563-4e4c-bfa4-56a4d10bcdc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# Configure the training\n",
        "num_epochs = 1\n",
        "\n",
        "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
        "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
        "          evaluator=evaluator,\n",
        "          epochs=num_epochs,\n",
        "          evaluation_steps=1000,\n",
        "          warmup_steps=warmup_steps,\n",
        "          output_path=model_save_path\n",
        "          )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9c5970de474a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwarmup_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#10% of train data for warm-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Warmup-steps: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ174o5CqLlw",
        "colab_type": "text"
      },
      "source": [
        "# After fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1N_eHMC_hhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jbCZKrn3tkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = SentenceTransformer('/content/output/training_nli_bert-2020-01-13_14-53-24')\n",
        "#model = SentenceTransformer('/content/output/training_nli_bert-2020-01-23_17-06-00')\n",
        "#model = SentenceTransformer('/content/gdrive/output/training_nli_bert-2020-02-09_11-48-02')\n",
        "model = SentenceTransformer('/content/drive/My Drive/models/training_nli_bert-2020-02-09_13-04-35')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfvOkkbwrUj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []\n",
        "for pair in PAIRS:\n",
        "    results += evaluate_language_pair(model, pair_name=pair, batch_size=50)\n",
        "df_finetuned = pd.DataFrame(results, columns=[\"from\", \"to\", \"correct\", \"total\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f9ZEcAQrbO0",
        "colab_type": "code",
        "outputId": "24e0ccff-d054-4eff-9f93-4e603ea08ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "df_finetuned"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>correct</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>de</td>\n",
              "      <td>en</td>\n",
              "      <td>145</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "      <td>120</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>de</td>\n",
              "      <td>ru</td>\n",
              "      <td>131</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ru</td>\n",
              "      <td>de</td>\n",
              "      <td>124</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  from  to  correct  total\n",
              "0   de  en      145    502\n",
              "1   en  de      120    502\n",
              "2   de  ru      131    502\n",
              "3   ru  de      124    502"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pirQqWKjruUU",
        "colab_type": "code",
        "outputId": "2e1c4de5-cf35-41e6-dde1-bdb4e59c8210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "df_baseline_mean"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>correct</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>de</td>\n",
              "      <td>en</td>\n",
              "      <td>210</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "      <td>194</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>de</td>\n",
              "      <td>ru</td>\n",
              "      <td>200</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ru</td>\n",
              "      <td>de</td>\n",
              "      <td>184</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  from  to  correct  total\n",
              "0   de  en      210    502\n",
              "1   en  de      194    502\n",
              "2   de  ru      200    502\n",
              "3   ru  de      184    502"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgIUK7aury2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embedding_model = models.BERT('bert-base-multilingual-cased')\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=False,\n",
        "                               pooling_mode_cls_token=True,\n",
        "                               pooling_mode_max_tokens=False)\n",
        "\n",
        "model_cls = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbmeP7ooto49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "c4d4d701-b157-42ac-db65-f1b08204c05b"
      },
      "source": [
        "results = []\n",
        "for pair in PAIRS:\n",
        "    results += evaluate_language_pair(model_cls, pair_name=pair, batch_size=50)\n",
        "df_baseline_cls = pd.DataFrame(results, columns=[\"from\", \"to\", \"correct\", \"total\"])\n",
        "df_baseline_cls"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>correct</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>de</td>\n",
              "      <td>en</td>\n",
              "      <td>57</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "      <td>104</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>de</td>\n",
              "      <td>ru</td>\n",
              "      <td>88</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ru</td>\n",
              "      <td>de</td>\n",
              "      <td>123</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  from  to  correct  total\n",
              "0   de  en       57    502\n",
              "1   en  de      104    502\n",
              "2   de  ru       88    502\n",
              "3   ru  de      123    502"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THX7EAm9tvoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embedding_model = models.BERT('bert-base-multilingual-cased')\n",
        "# Apply mean pooling to get one fixed sized sentence vector\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=False,\n",
        "                               pooling_mode_cls_token=False,\n",
        "                               pooling_mode_max_tokens=True)\n",
        "model_max = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO5labgOuah9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "6ba2c271-3858-47f7-d50e-180d6ff021d4"
      },
      "source": [
        "results = []\n",
        "for pair in PAIRS:\n",
        "    results += evaluate_language_pair(model_max, pair_name=pair, batch_size=50)\n",
        "df_baseline_max = pd.DataFrame(results, columns=[\"from\", \"to\", \"correct\", \"total\"])\n",
        "df_baseline_max"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>correct</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>de</td>\n",
              "      <td>en</td>\n",
              "      <td>107</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "      <td>147</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>de</td>\n",
              "      <td>ru</td>\n",
              "      <td>122</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ru</td>\n",
              "      <td>de</td>\n",
              "      <td>109</td>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  from  to  correct  total\n",
              "0   de  en      107    502\n",
              "1   en  de      147    502\n",
              "2   de  ru      122    502\n",
              "3   ru  de      109    502"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz6InpLOusVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_baseline_mean[\"err_mean\"] = 1 - df_baseline_mean[\"correct\"] / df_baseline_mean[\"total\"]\n",
        "df_baseline_max[\"err_max\"] = 1 - df_baseline_max[\"correct\"] / df_baseline_max[\"total\"]\n",
        "df_baseline_cls[\"err_cls\"] = 1 - df_baseline_cls[\"correct\"] / df_baseline_cls[\"total\"]\n",
        "df_finetuned[\"err_finetuned\"] = 1 - df_finetuned[\"correct\"] / df_finetuned[\"total\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yep9v95ivngh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "0e5f4bd7-16af-44bd-8143-78cdcc0aea31"
      },
      "source": [
        "df_err = pd.concat([\n",
        "    df.set_index([\"from\", \"to\"]).drop([\"correct\", \"total\"], axis=1)\n",
        "    for df in (df_baseline_mean, df_baseline_max, df_baseline_cls, df_finetuned)\n",
        "], axis=1)\n",
        "df_err"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>err_mean</th>\n",
              "      <th>err_max</th>\n",
              "      <th>err_cls</th>\n",
              "      <th>err_finetuned</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>de</th>\n",
              "      <th>en</th>\n",
              "      <td>0.581673</td>\n",
              "      <td>0.786853</td>\n",
              "      <td>0.886454</td>\n",
              "      <td>0.711155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>en</th>\n",
              "      <th>de</th>\n",
              "      <td>0.613546</td>\n",
              "      <td>0.707171</td>\n",
              "      <td>0.792829</td>\n",
              "      <td>0.760956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>de</th>\n",
              "      <th>ru</th>\n",
              "      <td>0.601594</td>\n",
              "      <td>0.756972</td>\n",
              "      <td>0.824701</td>\n",
              "      <td>0.739044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ru</th>\n",
              "      <th>de</th>\n",
              "      <td>0.633466</td>\n",
              "      <td>0.782869</td>\n",
              "      <td>0.754980</td>\n",
              "      <td>0.752988</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         err_mean   err_max   err_cls  err_finetuned\n",
              "from to                                             \n",
              "de   en  0.581673  0.786853  0.886454       0.711155\n",
              "en   de  0.613546  0.707171  0.792829       0.760956\n",
              "de   ru  0.601594  0.756972  0.824701       0.739044\n",
              "ru   de  0.633466  0.782869  0.754980       0.752988"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    }
  ]
}