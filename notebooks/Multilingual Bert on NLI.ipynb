{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Multilingual Bert on NLI.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfsrReg9-bXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "a0d73dfc-fc68-478f-f8a9-cc54e89ecfcf"
      },
      "source": [
        "!pip install faiss"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting faiss\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/1c/4ae6cb87cf0c09c25561ea48db11e25713b25c580909902a92c090b377c0/faiss-1.5.3-cp36-cp36m-manylinux1_x86_64.whl (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 59kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from faiss) (1.17.5)\n",
            "Installing collected packages: faiss\n",
            "Successfully installed faiss-1.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3vyiIx4-hqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "92cd828f-1e24-475f-82ed-c5013d1b58bf"
      },
      "source": [
        "!pip install swigfaiss"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement swigfaiss (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for swigfaiss\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x_z1EYi_DFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "c314b294-abda-4eb3-9756-ad1fcc40d49a"
      },
      "source": [
        "!pip install sentence_transformers"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.6/dist-packages (0.2.5)\n",
            "Requirement already satisfied: transformers==2.3.0 in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (1.17.5)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (1.3.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (0.22.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (4.28.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence_transformers) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence_transformers) (1.10.47)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence_transformers) (0.1.85)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence_transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence_transformers) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence_transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence_transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0->sentence_transformers) (7.0)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence_transformers) (1.13.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence_transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence_transformers) (0.2.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence_transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence_transformers) (2.8)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers==2.3.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers==2.3.0->sentence_transformers) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBSUWQu5_IGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83QMfI5L96uD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "The system trains BERT on the SNLI + MultiNLI (AllNLI) dataset\n",
        "with softmax loss function. At every 1000 training steps, the model is evaluated on the\n",
        "STS benchmark dataset\n",
        "\"\"\"\n",
        "import math\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import joblib\n",
        "#import faiss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import models, losses\n",
        "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "from sentence_transformers.readers import *\n",
        "from sentence_transformers.util import batch_to_device\n",
        "from sentence_transformers.readers.InputExample import InputExample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsoS002q-TK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7AiYetp96ub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Just some code to print debug information to stdout\n",
        "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
        "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "                    level=logging.INFO,\n",
        "                    handlers=[LoggingHandler()])\n",
        "#### /print debug information to stdout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "3p8FTFes96uk",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "4MeM8sER96uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the dataset\n",
        "batch_size = 16\n",
        "nli_reader = NLIDataReader('datasets/AllNLI')\n",
        "sts_reader = STSDataReader('datasets/stsbenchmark')\n",
        "train_num_labels = nli_reader.get_num_labels()\n",
        "model_save_path = 'output/training_nli_bert-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "KKP9hUaL96uw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "outputId": "7a16f1ae-4b08-4aa9-c963-634fbd27bef1"
      },
      "source": [
        "# Use BERT for mapping tokens to embeddings\n",
        "# Using manually downloaded model data:\n",
        "#word_embedding_model = models.BERT('../models/bert-base-multilingual-cased/')\n",
        "# Or you can let the library handle the downloading and caching for you:\n",
        "word_embedding_model = models.BERT('bert-base-multilingual-cased')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-11 09:57:41 - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /root/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.83b0fa3d7f1ac0e113ad300189a938c6f14d0588a4200f30eef109d0a047c484\n",
            "2020-01-11 09:57:41 - Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "2020-01-11 09:57:41 - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /root/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
            "2020-01-11 09:57:45 - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /root/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "7AbYf1sb96u4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def children(m):\n",
        "    return m if isinstance(m, (list, tuple)) else list(m.children())\n",
        "\n",
        "\n",
        "def set_trainable_attr(m, b):\n",
        "    m.trainable = b\n",
        "    for p in m.parameters():\n",
        "        p.requires_grad = b\n",
        "\n",
        "\n",
        "def apply_leaf(m, f):\n",
        "    c = children(m)\n",
        "    if isinstance(m, nn.Module):\n",
        "        f(m)\n",
        "    if len(c) > 0:\n",
        "        for l in c:\n",
        "            apply_leaf(l, f)\n",
        "\n",
        "\n",
        "def set_trainable(l, b):\n",
        "    apply_leaf(l, lambda m: set_trainable_attr(m, b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "vnuJzL2h96vB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "12ba889f-e7d6-474b-c0c2-59118bc851e9"
      },
      "source": [
        "set_trainable(word_embedding_model.bert.embeddings.word_embeddings, False)\n",
        "print(word_embedding_model.bert.embeddings.word_embeddings.weight.requires_grad)\n",
        "print(word_embedding_model.bert.embeddings.position_embeddings.weight.requires_grad)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "mTLtkL4D96vJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "63dd9a20-5e01-46c2-8b7e-3431d8d69152"
      },
      "source": [
        "# Apply mean pooling to get one fixed sized sentence vector\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=True,\n",
        "                               pooling_mode_cls_token=False,\n",
        "                               pooling_mode_max_tokens=False)\n",
        "\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-11 10:08:29 - Use pytorch device: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "IBhMip8e96vS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "ac5760bf-ae2d-4150-9ae0-050523d0f9a9"
      },
      "source": [
        "# # Convert the dataset to a DataLoader ready for training\n",
        "logging.info(\"Read AllNLI train dataset\")\n",
        "train_data = SentencesDataset(nli_reader.get_examples('train.gz'), model=model)\n",
        "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "train_loss = losses.SoftmaxLoss(\n",
        "    model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=train_num_labels)\n",
        "\n",
        "logging.info(\"Read STSbenchmark dev dataset\")\n",
        "dev_data = SentencesDataset(examples=sts_reader.get_examples('sts-dev.csv'), model=model)\n",
        "dev_dataloader = DataLoader(dev_data, shuffle=False, batch_size=batch_size)\n",
        "evaluator = EmbeddingSimilarityEvaluator(dev_dataloader)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-11 10:08:57 - Read AllNLI train dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-988c4a53b0a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read AllNLI train dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentencesDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnli_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m train_loss = losses.SoftmaxLoss(\n\u001b[1;32m      5\u001b[0m     model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=train_num_labels)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sentence_transformers/readers/NLIDataReader.py\u001b[0m in \u001b[0;36mget_examples\u001b[0;34m(self, filename, max_examples)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \"\"\"\n\u001b[1;32m     20\u001b[0m         s1 = gzip.open(os.path.join(self.dataset_folder, 's1.' + filename),\n\u001b[0;32m---> 21\u001b[0;31m                        mode=\"rt\", encoding=\"utf-8\").readlines()\n\u001b[0m\u001b[1;32m     22\u001b[0m         s2 = gzip.open(os.path.join(self.dataset_folder, 's2.' + filename),\n\u001b[1;32m     23\u001b[0m                        mode=\"rt\", encoding=\"utf-8\").readlines()\n",
            "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/AllNLI/s1.train.gz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "jmzZKC6f96vZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "aa900593-212e-4b04-ce86-877f7935ab09"
      },
      "source": [
        "# joblib.dump(train_data, \"allnli_train_dataset.jl\")\n",
        "# joblib.dump(dev_data, \"sts_dev_dataset.jl\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b812c167c86e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"allnli_train_dataset.jl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sts_dev_dataset.jl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "WBSbZiQc96vi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "70ce0567-c910-433c-f8f7-21e44b59e845"
      },
      "source": [
        "# Convert the dataset to a DataLoader ready for training\n",
        "#logging.info(\"Read AllNLI train dataset\")\n",
        "#train_data = joblib.load(\"allnli_train_dataset.jl\")\n",
        "#train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "#train_loss = losses.SoftmaxLoss(\n",
        "#    model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=train_num_labels)\n",
        "\n",
        "#logging.info(\"Read STSbenchmark dev dataset\")\n",
        "#dev_data = joblib.load(\"sts_dev_dataset.jl\")\n",
        "#dev_dataloader = DataLoader(dev_data, shuffle=False, batch_size=batch_size)\n",
        "#evaluator = EmbeddingSimilarityEvaluator(dev_dataloader)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-11 09:46:02 - Read\n",
            "2020-01-11 09:46:02 - Read\n",
            "2020-01-11 09:46:02 - Read\n",
            "2020-01-11 09:46:02 - Read\n",
            "2020-01-11 09:46:02 - Read\n",
            "2020-01-11 09:46:02 - Read AllNLI train dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-2a939c2ed66e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read AllNLI train dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allnli_train_dataset.jl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m train_loss = losses.SoftmaxLoss(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'allnli_train_dataset.jl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "J4RbOGt196vs",
        "colab_type": "code",
        "colab": {
          "referenced_widgets": [
            "947ad56f92af451e8a54b72cda019ab7",
            "e830377db82148c3a6184c08981c1456"
          ]
        },
        "outputId": "b7058483-acb8-4745-86cb-7d093a22afc5"
      },
      "source": [
        "# Configure the training\n",
        "num_epochs = 1\n",
        "\n",
        "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
        "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
        "          evaluator=evaluator,\n",
        "          epochs=num_epochs,\n",
        "          evaluation_steps=1000,\n",
        "          warmup_steps=warmup_steps,\n",
        "          output_path=model_save_path\n",
        "          )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 21:51:44 - Warmup-steps: 5888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "947ad56f92af451e8a54b72cda019ab7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e830377db82148c3a6184c08981c1456",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Iteration', max=58880, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 26.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 21:56:24 - Evaluation the model on  dataset in epoch 0 after 1000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.75it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 21:56:30 - Cosine-Similarity :\tPearson: 0.5370\tSpearman: 0.5462\n",
            "2019-09-22 21:56:30 - Manhattan-Distance:\tPearson: 0.5615\tSpearman: 0.5749\n",
            "2019-09-22 21:56:30 - Euclidean-Distance:\tPearson: 0.5604\tSpearman: 0.5736\n",
            "2019-09-22 21:56:30 - Dot-Product-Similarity:\tPearson: 0.2355\tSpearman: 0.2451\n",
            "2019-09-22 21:56:30 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 26.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:01:13 - Evaluation the model on  dataset in epoch 0 after 2000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.76it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:01:18 - Cosine-Similarity :\tPearson: 0.5260\tSpearman: 0.5738\n",
            "2019-09-22 22:01:18 - Manhattan-Distance:\tPearson: 0.5595\tSpearman: 0.5798\n",
            "2019-09-22 22:01:18 - Euclidean-Distance:\tPearson: 0.5559\tSpearman: 0.5785\n",
            "2019-09-22 22:01:18 - Dot-Product-Similarity:\tPearson: 0.3708\tSpearman: 0.3659\n",
            "2019-09-22 22:01:18 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:06:00 - Evaluation the model on  dataset in epoch 0 after 3000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:06:05 - Cosine-Similarity :\tPearson: 0.4663\tSpearman: 0.5548\n",
            "2019-09-22 22:06:05 - Manhattan-Distance:\tPearson: 0.5266\tSpearman: 0.5633\n",
            "2019-09-22 22:06:05 - Euclidean-Distance:\tPearson: 0.5203\tSpearman: 0.5614\n",
            "2019-09-22 22:06:05 - Dot-Product-Similarity:\tPearson: 0.3776\tSpearman: 0.3856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:10:52 - Evaluation the model on  dataset in epoch 0 after 4000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:10:57 - Cosine-Similarity :\tPearson: 0.5182\tSpearman: 0.5717\n",
            "2019-09-22 22:10:57 - Manhattan-Distance:\tPearson: 0.5653\tSpearman: 0.5842\n",
            "2019-09-22 22:10:57 - Euclidean-Distance:\tPearson: 0.5627\tSpearman: 0.5835\n",
            "2019-09-22 22:10:57 - Dot-Product-Similarity:\tPearson: 0.4042\tSpearman: 0.4053\n",
            "2019-09-22 22:10:57 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:15:51 - Evaluation the model on  dataset in epoch 0 after 5000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:15:57 - Cosine-Similarity :\tPearson: 0.5496\tSpearman: 0.5882\n",
            "2019-09-22 22:15:57 - Manhattan-Distance:\tPearson: 0.5766\tSpearman: 0.5877\n",
            "2019-09-22 22:15:57 - Euclidean-Distance:\tPearson: 0.5728\tSpearman: 0.5865\n",
            "2019-09-22 22:15:57 - Dot-Product-Similarity:\tPearson: 0.4743\tSpearman: 0.4912\n",
            "2019-09-22 22:15:57 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:20:44 - Evaluation the model on  dataset in epoch 0 after 6000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:20:50 - Cosine-Similarity :\tPearson: 0.5798\tSpearman: 0.6150\n",
            "2019-09-22 22:20:50 - Manhattan-Distance:\tPearson: 0.6147\tSpearman: 0.6245\n",
            "2019-09-22 22:20:50 - Euclidean-Distance:\tPearson: 0.6117\tSpearman: 0.6232\n",
            "2019-09-22 22:20:50 - Dot-Product-Similarity:\tPearson: 0.4848\tSpearman: 0.4872\n",
            "2019-09-22 22:20:50 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:25:32 - Evaluation the model on  dataset in epoch 0 after 7000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.75it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:25:37 - Cosine-Similarity :\tPearson: 0.5972\tSpearman: 0.6276\n",
            "2019-09-22 22:25:37 - Manhattan-Distance:\tPearson: 0.6268\tSpearman: 0.6302\n",
            "2019-09-22 22:25:37 - Euclidean-Distance:\tPearson: 0.6257\tSpearman: 0.6296\n",
            "2019-09-22 22:25:37 - Dot-Product-Similarity:\tPearson: 0.5632\tSpearman: 0.5640\n",
            "2019-09-22 22:25:37 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:30:21 - Evaluation the model on  dataset in epoch 0 after 8000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.79it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:30:26 - Cosine-Similarity :\tPearson: 0.6190\tSpearman: 0.6466\n",
            "2019-09-22 22:30:26 - Manhattan-Distance:\tPearson: 0.6389\tSpearman: 0.6455\n",
            "2019-09-22 22:30:26 - Euclidean-Distance:\tPearson: 0.6352\tSpearman: 0.6438\n",
            "2019-09-22 22:30:26 - Dot-Product-Similarity:\tPearson: 0.5180\tSpearman: 0.5192\n",
            "2019-09-22 22:30:26 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:35:08 - Evaluation the model on  dataset in epoch 0 after 9000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.79it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:35:14 - Cosine-Similarity :\tPearson: 0.6041\tSpearman: 0.6379\n",
            "2019-09-22 22:35:14 - Manhattan-Distance:\tPearson: 0.6357\tSpearman: 0.6399\n",
            "2019-09-22 22:35:14 - Euclidean-Distance:\tPearson: 0.6340\tSpearman: 0.6389\n",
            "2019-09-22 22:35:14 - Dot-Product-Similarity:\tPearson: 0.5534\tSpearman: 0.5527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:39:54 - Evaluation the model on  dataset in epoch 0 after 10000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.79it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:40:00 - Cosine-Similarity :\tPearson: 0.6271\tSpearman: 0.6507\n",
            "2019-09-22 22:40:00 - Manhattan-Distance:\tPearson: 0.6458\tSpearman: 0.6494\n",
            "2019-09-22 22:40:00 - Euclidean-Distance:\tPearson: 0.6458\tSpearman: 0.6492\n",
            "2019-09-22 22:40:00 - Dot-Product-Similarity:\tPearson: 0.5580\tSpearman: 0.5548\n",
            "2019-09-22 22:40:00 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:44:43 - Evaluation the model on  dataset in epoch 0 after 11000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:44:48 - Cosine-Similarity :\tPearson: 0.6429\tSpearman: 0.6576\n",
            "2019-09-22 22:44:48 - Manhattan-Distance:\tPearson: 0.6629\tSpearman: 0.6596\n",
            "2019-09-22 22:44:48 - Euclidean-Distance:\tPearson: 0.6619\tSpearman: 0.6591\n",
            "2019-09-22 22:44:48 - Dot-Product-Similarity:\tPearson: 0.5923\tSpearman: 0.5854\n",
            "2019-09-22 22:44:48 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:49:30 - Evaluation the model on  dataset in epoch 0 after 12000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:49:36 - Cosine-Similarity :\tPearson: 0.6285\tSpearman: 0.6557\n",
            "2019-09-22 22:49:36 - Manhattan-Distance:\tPearson: 0.6595\tSpearman: 0.6595\n",
            "2019-09-22 22:49:36 - Euclidean-Distance:\tPearson: 0.6587\tSpearman: 0.6595\n",
            "2019-09-22 22:49:36 - Dot-Product-Similarity:\tPearson: 0.5837\tSpearman: 0.5840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:54:17 - Evaluation the model on  dataset in epoch 0 after 13000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:54:22 - Cosine-Similarity :\tPearson: 0.6414\tSpearman: 0.6632\n",
            "2019-09-22 22:54:22 - Manhattan-Distance:\tPearson: 0.6668\tSpearman: 0.6664\n",
            "2019-09-22 22:54:22 - Euclidean-Distance:\tPearson: 0.6650\tSpearman: 0.6650\n",
            "2019-09-22 22:54:22 - Dot-Product-Similarity:\tPearson: 0.6073\tSpearman: 0.6063\n",
            "2019-09-22 22:54:22 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:59:06 - Evaluation the model on  dataset in epoch 0 after 14000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 22:59:11 - Cosine-Similarity :\tPearson: 0.6634\tSpearman: 0.6855\n",
            "2019-09-22 22:59:11 - Manhattan-Distance:\tPearson: 0.6865\tSpearman: 0.6866\n",
            "2019-09-22 22:59:11 - Euclidean-Distance:\tPearson: 0.6865\tSpearman: 0.6864\n",
            "2019-09-22 22:59:11 - Dot-Product-Similarity:\tPearson: 0.6358\tSpearman: 0.6362\n",
            "2019-09-22 22:59:11 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:03:55 - Evaluation the model on  dataset in epoch 0 after 15000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:04:00 - Cosine-Similarity :\tPearson: 0.6600\tSpearman: 0.6756\n",
            "2019-09-22 23:04:00 - Manhattan-Distance:\tPearson: 0.6804\tSpearman: 0.6779\n",
            "2019-09-22 23:04:00 - Euclidean-Distance:\tPearson: 0.6801\tSpearman: 0.6776\n",
            "2019-09-22 23:04:00 - Dot-Product-Similarity:\tPearson: 0.6308\tSpearman: 0.6251\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:08:41 - Evaluation the model on  dataset in epoch 0 after 16000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:08:47 - Cosine-Similarity :\tPearson: 0.6847\tSpearman: 0.7128\n",
            "2019-09-22 23:08:47 - Manhattan-Distance:\tPearson: 0.7150\tSpearman: 0.7140\n",
            "2019-09-22 23:08:47 - Euclidean-Distance:\tPearson: 0.7127\tSpearman: 0.7130\n",
            "2019-09-22 23:08:47 - Dot-Product-Similarity:\tPearson: 0.6570\tSpearman: 0.6613\n",
            "2019-09-22 23:08:47 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:13:29 - Evaluation the model on  dataset in epoch 0 after 17000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:13:35 - Cosine-Similarity :\tPearson: 0.6780\tSpearman: 0.7024\n",
            "2019-09-22 23:13:35 - Manhattan-Distance:\tPearson: 0.7033\tSpearman: 0.7039\n",
            "2019-09-22 23:13:35 - Euclidean-Distance:\tPearson: 0.7032\tSpearman: 0.7039\n",
            "2019-09-22 23:13:35 - Dot-Product-Similarity:\tPearson: 0.6479\tSpearman: 0.6527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:18:16 - Evaluation the model on  dataset in epoch 0 after 18000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:18:21 - Cosine-Similarity :\tPearson: 0.6791\tSpearman: 0.7082\n",
            "2019-09-22 23:18:21 - Manhattan-Distance:\tPearson: 0.7087\tSpearman: 0.7084\n",
            "2019-09-22 23:18:21 - Euclidean-Distance:\tPearson: 0.7071\tSpearman: 0.7071\n",
            "2019-09-22 23:18:21 - Dot-Product-Similarity:\tPearson: 0.6612\tSpearman: 0.6685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:23:04 - Evaluation the model on  dataset in epoch 0 after 19000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:23:09 - Cosine-Similarity :\tPearson: 0.7070\tSpearman: 0.7320\n",
            "2019-09-22 23:23:09 - Manhattan-Distance:\tPearson: 0.7342\tSpearman: 0.7334\n",
            "2019-09-22 23:23:09 - Euclidean-Distance:\tPearson: 0.7332\tSpearman: 0.7326\n",
            "2019-09-22 23:23:09 - Dot-Product-Similarity:\tPearson: 0.6896\tSpearman: 0.6970\n",
            "2019-09-22 23:23:09 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:27:54 - Evaluation the model on  dataset in epoch 0 after 20000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:27:59 - Cosine-Similarity :\tPearson: 0.7017\tSpearman: 0.7234\n",
            "2019-09-22 23:27:59 - Manhattan-Distance:\tPearson: 0.7271\tSpearman: 0.7257\n",
            "2019-09-22 23:27:59 - Euclidean-Distance:\tPearson: 0.7269\tSpearman: 0.7256\n",
            "2019-09-22 23:27:59 - Dot-Product-Similarity:\tPearson: 0.6870\tSpearman: 0.6932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:32:42 - Evaluation the model on  dataset in epoch 0 after 21000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:32:47 - Cosine-Similarity :\tPearson: 0.7121\tSpearman: 0.7325\n",
            "2019-09-22 23:32:47 - Manhattan-Distance:\tPearson: 0.7366\tSpearman: 0.7352\n",
            "2019-09-22 23:32:47 - Euclidean-Distance:\tPearson: 0.7357\tSpearman: 0.7346\n",
            "2019-09-22 23:32:47 - Dot-Product-Similarity:\tPearson: 0.6985\tSpearman: 0.7058\n",
            "2019-09-22 23:32:47 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:37:28 - Evaluation the model on  dataset in epoch 0 after 22000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:37:34 - Cosine-Similarity :\tPearson: 0.7261\tSpearman: 0.7463\n",
            "2019-09-22 23:37:34 - Manhattan-Distance:\tPearson: 0.7472\tSpearman: 0.7466\n",
            "2019-09-22 23:37:34 - Euclidean-Distance:\tPearson: 0.7460\tSpearman: 0.7458\n",
            "2019-09-22 23:37:34 - Dot-Product-Similarity:\tPearson: 0.7170\tSpearman: 0.7238\n",
            "2019-09-22 23:37:34 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:42:15 - Evaluation the model on  dataset in epoch 0 after 23000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:42:20 - Cosine-Similarity :\tPearson: 0.7195\tSpearman: 0.7417\n",
            "2019-09-22 23:42:20 - Manhattan-Distance:\tPearson: 0.7442\tSpearman: 0.7432\n",
            "2019-09-22 23:42:20 - Euclidean-Distance:\tPearson: 0.7414\tSpearman: 0.7407\n",
            "2019-09-22 23:42:20 - Dot-Product-Similarity:\tPearson: 0.7115\tSpearman: 0.7211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:47:03 - Evaluation the model on  dataset in epoch 0 after 24000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:47:09 - Cosine-Similarity :\tPearson: 0.7128\tSpearman: 0.7383\n",
            "2019-09-22 23:47:09 - Manhattan-Distance:\tPearson: 0.7442\tSpearman: 0.7426\n",
            "2019-09-22 23:47:09 - Euclidean-Distance:\tPearson: 0.7423\tSpearman: 0.7410\n",
            "2019-09-22 23:47:09 - Dot-Product-Similarity:\tPearson: 0.6969\tSpearman: 0.7053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:51:49 - Evaluation the model on  dataset in epoch 0 after 25000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:51:54 - Cosine-Similarity :\tPearson: 0.7239\tSpearman: 0.7438\n",
            "2019-09-22 23:51:54 - Manhattan-Distance:\tPearson: 0.7511\tSpearman: 0.7498\n",
            "2019-09-22 23:51:54 - Euclidean-Distance:\tPearson: 0.7496\tSpearman: 0.7484\n",
            "2019-09-22 23:51:54 - Dot-Product-Similarity:\tPearson: 0.7011\tSpearman: 0.7053\n",
            "2019-09-22 23:51:54 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:56:39 - Evaluation the model on  dataset in epoch 0 after 26000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-22 23:56:44 - Cosine-Similarity :\tPearson: 0.7228\tSpearman: 0.7429\n",
            "2019-09-22 23:56:44 - Manhattan-Distance:\tPearson: 0.7471\tSpearman: 0.7441\n",
            "2019-09-22 23:56:44 - Euclidean-Distance:\tPearson: 0.7456\tSpearman: 0.7431\n",
            "2019-09-22 23:56:44 - Dot-Product-Similarity:\tPearson: 0.7093\tSpearman: 0.7144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:01:24 - Evaluation the model on  dataset in epoch 0 after 27000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:01:29 - Cosine-Similarity :\tPearson: 0.7192\tSpearman: 0.7366\n",
            "2019-09-23 00:01:29 - Manhattan-Distance:\tPearson: 0.7414\tSpearman: 0.7392\n",
            "2019-09-23 00:01:29 - Euclidean-Distance:\tPearson: 0.7395\tSpearman: 0.7375\n",
            "2019-09-23 00:01:29 - Dot-Product-Similarity:\tPearson: 0.7024\tSpearman: 0.7069\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:06:07 - Evaluation the model on  dataset in epoch 0 after 28000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:06:12 - Cosine-Similarity :\tPearson: 0.7265\tSpearman: 0.7459\n",
            "2019-09-23 00:06:12 - Manhattan-Distance:\tPearson: 0.7485\tSpearman: 0.7475\n",
            "2019-09-23 00:06:12 - Euclidean-Distance:\tPearson: 0.7467\tSpearman: 0.7461\n",
            "2019-09-23 00:06:12 - Dot-Product-Similarity:\tPearson: 0.7151\tSpearman: 0.7213\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:10:56 - Evaluation the model on  dataset in epoch 0 after 29000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:11:01 - Cosine-Similarity :\tPearson: 0.7357\tSpearman: 0.7533\n",
            "2019-09-23 00:11:01 - Manhattan-Distance:\tPearson: 0.7565\tSpearman: 0.7550\n",
            "2019-09-23 00:11:01 - Euclidean-Distance:\tPearson: 0.7551\tSpearman: 0.7534\n",
            "2019-09-23 00:11:01 - Dot-Product-Similarity:\tPearson: 0.7226\tSpearman: 0.7279\n",
            "2019-09-23 00:11:01 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:15:45 - Evaluation the model on  dataset in epoch 0 after 30000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:15:51 - Cosine-Similarity :\tPearson: 0.7290\tSpearman: 0.7489\n",
            "2019-09-23 00:15:51 - Manhattan-Distance:\tPearson: 0.7548\tSpearman: 0.7543\n",
            "2019-09-23 00:15:51 - Euclidean-Distance:\tPearson: 0.7524\tSpearman: 0.7524\n",
            "2019-09-23 00:15:51 - Dot-Product-Similarity:\tPearson: 0.7084\tSpearman: 0.7145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:20:31 - Evaluation the model on  dataset in epoch 0 after 31000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:20:36 - Cosine-Similarity :\tPearson: 0.7249\tSpearman: 0.7440\n",
            "2019-09-23 00:20:36 - Manhattan-Distance:\tPearson: 0.7482\tSpearman: 0.7468\n",
            "2019-09-23 00:20:36 - Euclidean-Distance:\tPearson: 0.7462\tSpearman: 0.7453\n",
            "2019-09-23 00:20:36 - Dot-Product-Similarity:\tPearson: 0.7125\tSpearman: 0.7193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:25:19 - Evaluation the model on  dataset in epoch 0 after 32000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:25:24 - Cosine-Similarity :\tPearson: 0.7335\tSpearman: 0.7486\n",
            "2019-09-23 00:25:24 - Manhattan-Distance:\tPearson: 0.7539\tSpearman: 0.7511\n",
            "2019-09-23 00:25:24 - Euclidean-Distance:\tPearson: 0.7536\tSpearman: 0.7513\n",
            "2019-09-23 00:25:24 - Dot-Product-Similarity:\tPearson: 0.7155\tSpearman: 0.7180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:30:01 - Evaluation the model on  dataset in epoch 0 after 33000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:30:06 - Cosine-Similarity :\tPearson: 0.7405\tSpearman: 0.7563\n",
            "2019-09-23 00:30:06 - Manhattan-Distance:\tPearson: 0.7598\tSpearman: 0.7582\n",
            "2019-09-23 00:30:06 - Euclidean-Distance:\tPearson: 0.7586\tSpearman: 0.7569\n",
            "2019-09-23 00:30:06 - Dot-Product-Similarity:\tPearson: 0.7318\tSpearman: 0.7372\n",
            "2019-09-23 00:30:06 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:34:50 - Evaluation the model on  dataset in epoch 0 after 34000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:34:55 - Cosine-Similarity :\tPearson: 0.7402\tSpearman: 0.7585\n",
            "2019-09-23 00:34:55 - Manhattan-Distance:\tPearson: 0.7629\tSpearman: 0.7617\n",
            "2019-09-23 00:34:55 - Euclidean-Distance:\tPearson: 0.7618\tSpearman: 0.7611\n",
            "2019-09-23 00:34:55 - Dot-Product-Similarity:\tPearson: 0.7252\tSpearman: 0.7312\n",
            "2019-09-23 00:34:55 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:39:37 - Evaluation the model on  dataset in epoch 0 after 35000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:39:43 - Cosine-Similarity :\tPearson: 0.7426\tSpearman: 0.7609\n",
            "2019-09-23 00:39:43 - Manhattan-Distance:\tPearson: 0.7648\tSpearman: 0.7637\n",
            "2019-09-23 00:39:43 - Euclidean-Distance:\tPearson: 0.7632\tSpearman: 0.7626\n",
            "2019-09-23 00:39:43 - Dot-Product-Similarity:\tPearson: 0.7290\tSpearman: 0.7349\n",
            "2019-09-23 00:39:43 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:44:23 - Evaluation the model on  dataset in epoch 0 after 36000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:44:28 - Cosine-Similarity :\tPearson: 0.7383\tSpearman: 0.7552\n",
            "2019-09-23 00:44:28 - Manhattan-Distance:\tPearson: 0.7592\tSpearman: 0.7582\n",
            "2019-09-23 00:44:28 - Euclidean-Distance:\tPearson: 0.7585\tSpearman: 0.7581\n",
            "2019-09-23 00:44:28 - Dot-Product-Similarity:\tPearson: 0.7255\tSpearman: 0.7325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:49:06 - Evaluation the model on  dataset in epoch 0 after 37000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:49:11 - Cosine-Similarity :\tPearson: 0.7401\tSpearman: 0.7604\n",
            "2019-09-23 00:49:11 - Manhattan-Distance:\tPearson: 0.7639\tSpearman: 0.7632\n",
            "2019-09-23 00:49:11 - Euclidean-Distance:\tPearson: 0.7624\tSpearman: 0.7622\n",
            "2019-09-23 00:49:11 - Dot-Product-Similarity:\tPearson: 0.7268\tSpearman: 0.7340\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:53:48 - Evaluation the model on  dataset in epoch 0 after 38000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:53:53 - Cosine-Similarity :\tPearson: 0.7387\tSpearman: 0.7563\n",
            "2019-09-23 00:53:53 - Manhattan-Distance:\tPearson: 0.7592\tSpearman: 0.7593\n",
            "2019-09-23 00:53:53 - Euclidean-Distance:\tPearson: 0.7586\tSpearman: 0.7589\n",
            "2019-09-23 00:53:53 - Dot-Product-Similarity:\tPearson: 0.7245\tSpearman: 0.7315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:58:33 - Evaluation the model on  dataset in epoch 0 after 39000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 00:58:39 - Cosine-Similarity :\tPearson: 0.7491\tSpearman: 0.7660\n",
            "2019-09-23 00:58:39 - Manhattan-Distance:\tPearson: 0.7700\tSpearman: 0.7699\n",
            "2019-09-23 00:58:39 - Euclidean-Distance:\tPearson: 0.7697\tSpearman: 0.7698\n",
            "2019-09-23 00:58:39 - Dot-Product-Similarity:\tPearson: 0.7306\tSpearman: 0.7370\n",
            "2019-09-23 00:58:39 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:03:22 - Evaluation the model on  dataset in epoch 0 after 40000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:03:27 - Cosine-Similarity :\tPearson: 0.7474\tSpearman: 0.7673\n",
            "2019-09-23 01:03:27 - Manhattan-Distance:\tPearson: 0.7695\tSpearman: 0.7696\n",
            "2019-09-23 01:03:27 - Euclidean-Distance:\tPearson: 0.7687\tSpearman: 0.7692\n",
            "2019-09-23 01:03:27 - Dot-Product-Similarity:\tPearson: 0.7350\tSpearman: 0.7436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:08:10 - Evaluation the model on  dataset in epoch 0 after 41000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:08:15 - Cosine-Similarity :\tPearson: 0.7457\tSpearman: 0.7663\n",
            "2019-09-23 01:08:15 - Manhattan-Distance:\tPearson: 0.7688\tSpearman: 0.7688\n",
            "2019-09-23 01:08:15 - Euclidean-Distance:\tPearson: 0.7679\tSpearman: 0.7682\n",
            "2019-09-23 01:08:15 - Dot-Product-Similarity:\tPearson: 0.7330\tSpearman: 0.7434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:12:57 - Evaluation the model on  dataset in epoch 0 after 42000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:13:02 - Cosine-Similarity :\tPearson: 0.7465\tSpearman: 0.7631\n",
            "2019-09-23 01:13:02 - Manhattan-Distance:\tPearson: 0.7658\tSpearman: 0.7652\n",
            "2019-09-23 01:13:02 - Euclidean-Distance:\tPearson: 0.7651\tSpearman: 0.7650\n",
            "2019-09-23 01:13:02 - Dot-Product-Similarity:\tPearson: 0.7374\tSpearman: 0.7461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:17:44 - Evaluation the model on  dataset in epoch 0 after 43000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:17:49 - Cosine-Similarity :\tPearson: 0.7481\tSpearman: 0.7646\n",
            "2019-09-23 01:17:49 - Manhattan-Distance:\tPearson: 0.7668\tSpearman: 0.7669\n",
            "2019-09-23 01:17:49 - Euclidean-Distance:\tPearson: 0.7665\tSpearman: 0.7668\n",
            "2019-09-23 01:17:49 - Dot-Product-Similarity:\tPearson: 0.7361\tSpearman: 0.7438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:22:29 - Evaluation the model on  dataset in epoch 0 after 44000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:22:35 - Cosine-Similarity :\tPearson: 0.7433\tSpearman: 0.7610\n",
            "2019-09-23 01:22:35 - Manhattan-Distance:\tPearson: 0.7633\tSpearman: 0.7625\n",
            "2019-09-23 01:22:35 - Euclidean-Distance:\tPearson: 0.7628\tSpearman: 0.7625\n",
            "2019-09-23 01:22:35 - Dot-Product-Similarity:\tPearson: 0.7341\tSpearman: 0.7428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:27:16 - Evaluation the model on  dataset in epoch 0 after 45000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:27:21 - Cosine-Similarity :\tPearson: 0.7478\tSpearman: 0.7631\n",
            "2019-09-23 01:27:21 - Manhattan-Distance:\tPearson: 0.7661\tSpearman: 0.7656\n",
            "2019-09-23 01:27:21 - Euclidean-Distance:\tPearson: 0.7658\tSpearman: 0.7652\n",
            "2019-09-23 01:27:21 - Dot-Product-Similarity:\tPearson: 0.7388\tSpearman: 0.7467\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:32:03 - Evaluation the model on  dataset in epoch 0 after 46000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:32:08 - Cosine-Similarity :\tPearson: 0.7490\tSpearman: 0.7671\n",
            "2019-09-23 01:32:08 - Manhattan-Distance:\tPearson: 0.7694\tSpearman: 0.7690\n",
            "2019-09-23 01:32:08 - Euclidean-Distance:\tPearson: 0.7683\tSpearman: 0.7682\n",
            "2019-09-23 01:32:08 - Dot-Product-Similarity:\tPearson: 0.7423\tSpearman: 0.7536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:36:49 - Evaluation the model on  dataset in epoch 0 after 47000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:36:54 - Cosine-Similarity :\tPearson: 0.7538\tSpearman: 0.7686\n",
            "2019-09-23 01:36:54 - Manhattan-Distance:\tPearson: 0.7703\tSpearman: 0.7702\n",
            "2019-09-23 01:36:54 - Euclidean-Distance:\tPearson: 0.7694\tSpearman: 0.7699\n",
            "2019-09-23 01:36:54 - Dot-Product-Similarity:\tPearson: 0.7445\tSpearman: 0.7523\n",
            "2019-09-23 01:36:54 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:41:36 - Evaluation the model on  dataset in epoch 0 after 48000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:41:42 - Cosine-Similarity :\tPearson: 0.7555\tSpearman: 0.7702\n",
            "2019-09-23 01:41:42 - Manhattan-Distance:\tPearson: 0.7718\tSpearman: 0.7719\n",
            "2019-09-23 01:41:42 - Euclidean-Distance:\tPearson: 0.7715\tSpearman: 0.7719\n",
            "2019-09-23 01:41:42 - Dot-Product-Similarity:\tPearson: 0.7448\tSpearman: 0.7520\n",
            "2019-09-23 01:41:42 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:46:24 - Evaluation the model on  dataset in epoch 0 after 49000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:46:30 - Cosine-Similarity :\tPearson: 0.7482\tSpearman: 0.7631\n",
            "2019-09-23 01:46:30 - Manhattan-Distance:\tPearson: 0.7660\tSpearman: 0.7657\n",
            "2019-09-23 01:46:30 - Euclidean-Distance:\tPearson: 0.7656\tSpearman: 0.7652\n",
            "2019-09-23 01:46:30 - Dot-Product-Similarity:\tPearson: 0.7383\tSpearman: 0.7458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:51:13 - Evaluation the model on  dataset in epoch 0 after 50000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:51:18 - Cosine-Similarity :\tPearson: 0.7542\tSpearman: 0.7709\n",
            "2019-09-23 01:51:18 - Manhattan-Distance:\tPearson: 0.7732\tSpearman: 0.7732\n",
            "2019-09-23 01:51:18 - Euclidean-Distance:\tPearson: 0.7726\tSpearman: 0.7729\n",
            "2019-09-23 01:51:18 - Dot-Product-Similarity:\tPearson: 0.7466\tSpearman: 0.7562\n",
            "2019-09-23 01:51:18 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:55:59 - Evaluation the model on  dataset in epoch 0 after 51000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 01:56:04 - Cosine-Similarity :\tPearson: 0.7589\tSpearman: 0.7731\n",
            "2019-09-23 01:56:04 - Manhattan-Distance:\tPearson: 0.7749\tSpearman: 0.7752\n",
            "2019-09-23 01:56:04 - Euclidean-Distance:\tPearson: 0.7746\tSpearman: 0.7750\n",
            "2019-09-23 01:56:04 - Dot-Product-Similarity:\tPearson: 0.7490\tSpearman: 0.7559\n",
            "2019-09-23 01:56:04 - Save model to output/training_nli_bert-2019-09-22_21-50-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:00:47 - Evaluation the model on  dataset in epoch 0 after 52000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:00:53 - Cosine-Similarity :\tPearson: 0.7552\tSpearman: 0.7682\n",
            "2019-09-23 02:00:53 - Manhattan-Distance:\tPearson: 0.7703\tSpearman: 0.7708\n",
            "2019-09-23 02:00:53 - Euclidean-Distance:\tPearson: 0.7700\tSpearman: 0.7705\n",
            "2019-09-23 02:00:53 - Dot-Product-Similarity:\tPearson: 0.7451\tSpearman: 0.7514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 27.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:05:34 - Evaluation the model on  dataset in epoch 0 after 53000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:05:39 - Cosine-Similarity :\tPearson: 0.7556\tSpearman: 0.7692\n",
            "2019-09-23 02:05:39 - Manhattan-Distance:\tPearson: 0.7717\tSpearman: 0.7715\n",
            "2019-09-23 02:05:39 - Euclidean-Distance:\tPearson: 0.7718\tSpearman: 0.7718\n",
            "2019-09-23 02:05:39 - Dot-Product-Similarity:\tPearson: 0.7451\tSpearman: 0.7518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:10:21 - Evaluation the model on  dataset in epoch 0 after 54000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:10:26 - Cosine-Similarity :\tPearson: 0.7551\tSpearman: 0.7689\n",
            "2019-09-23 02:10:26 - Manhattan-Distance:\tPearson: 0.7712\tSpearman: 0.7708\n",
            "2019-09-23 02:10:26 - Euclidean-Distance:\tPearson: 0.7706\tSpearman: 0.7704\n",
            "2019-09-23 02:10:26 - Dot-Product-Similarity:\tPearson: 0.7462\tSpearman: 0.7529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:15:06 - Evaluation the model on  dataset in epoch 0 after 55000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:15:12 - Cosine-Similarity :\tPearson: 0.7564\tSpearman: 0.7689\n",
            "2019-09-23 02:15:12 - Manhattan-Distance:\tPearson: 0.7714\tSpearman: 0.7710\n",
            "2019-09-23 02:15:12 - Euclidean-Distance:\tPearson: 0.7709\tSpearman: 0.7708\n",
            "2019-09-23 02:15:12 - Dot-Product-Similarity:\tPearson: 0.7463\tSpearman: 0.7518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:19:56 - Evaluation the model on  dataset in epoch 0 after 56000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:20:02 - Cosine-Similarity :\tPearson: 0.7562\tSpearman: 0.7694\n",
            "2019-09-23 02:20:02 - Manhattan-Distance:\tPearson: 0.7717\tSpearman: 0.7715\n",
            "2019-09-23 02:20:02 - Euclidean-Distance:\tPearson: 0.7712\tSpearman: 0.7712\n",
            "2019-09-23 02:20:02 - Dot-Product-Similarity:\tPearson: 0.7466\tSpearman: 0.7529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:24:42 - Evaluation the model on  dataset in epoch 0 after 57000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:24:48 - Cosine-Similarity :\tPearson: 0.7568\tSpearman: 0.7701\n",
            "2019-09-23 02:24:48 - Manhattan-Distance:\tPearson: 0.7723\tSpearman: 0.7722\n",
            "2019-09-23 02:24:48 - Euclidean-Distance:\tPearson: 0.7716\tSpearman: 0.7717\n",
            "2019-09-23 02:24:48 - Dot-Product-Similarity:\tPearson: 0.7477\tSpearman: 0.7541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:29:28 - Evaluation the model on  dataset in epoch 0 after 58000 steps:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:29:33 - Cosine-Similarity :\tPearson: 0.7573\tSpearman: 0.7699\n",
            "2019-09-23 02:29:33 - Manhattan-Distance:\tPearson: 0.7724\tSpearman: 0.7723\n",
            "2019-09-23 02:29:33 - Euclidean-Distance:\tPearson: 0.7717\tSpearman: 0.7719\n",
            "2019-09-23 02:29:33 - Dot-Product-Similarity:\tPearson: 0.7480\tSpearman: 0.7538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating:   3%|▎         | 3/94 [00:00<00:03, 28.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2019-09-23 02:33:40 - Evaluation the model on  dataset after epoch 0:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 94/94 [00:05<00:00, 17.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 02:33:45 - Cosine-Similarity :\tPearson: 0.7573\tSpearman: 0.7699\n",
            "2019-09-23 02:33:45 - Manhattan-Distance:\tPearson: 0.7723\tSpearman: 0.7721\n",
            "2019-09-23 02:33:45 - Euclidean-Distance:\tPearson: 0.7717\tSpearman: 0.7719\n",
            "2019-09-23 02:33:45 - Dot-Product-Similarity:\tPearson: 0.7480\tSpearman: 0.7540\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "n7eNuNph96v3",
        "colab_type": "code",
        "colab": {},
        "outputId": "da361e57-824c-4431-dfa0-c50120b8ac61"
      },
      "source": [
        "model_save_path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output/training_nli_bert-2019-09-22_21-50-05'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "jM7RSFYN96v_",
        "colab_type": "code",
        "colab": {},
        "outputId": "f82fe58e-ca20-4fe4-d528-4f9cdc457184"
      },
      "source": [
        "##############################################################################\n",
        "#\n",
        "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
        "#\n",
        "##############################################################################\n",
        "\n",
        "model = SentenceTransformer(model_save_path)\n",
        "test_data = SentencesDataset(examples=sts_reader.get_examples(\"sts-test.csv\"), model=model)\n",
        "test_dataloader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
        "evaluator = EmbeddingSimilarityEvaluator(test_dataloader)\n",
        "\n",
        "model.evaluate(evaluator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 14:37:07 - Load pretrained SentenceTransformer: output/training_nli_bert-2019-09-22_21-50-05\n",
            "2019-09-23 14:37:07 - Load SentenceTransformer from folder: output/training_nli_bert-2019-09-22_21-50-05\n",
            "2019-09-23 14:37:07 - loading configuration file output/training_nli_bert-2019-09-22_21-50-05/0_BERT/config.json\n",
            "2019-09-23 14:37:07 - Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "2019-09-23 14:37:07 - loading weights file output/training_nli_bert-2019-09-22_21-50-05/0_BERT/pytorch_model.bin\n",
            "2019-09-23 14:37:09 - Model name 'output/training_nli_bert-2019-09-22_21-50-05/0_BERT' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'output/training_nli_bert-2019-09-22_21-50-05/0_BERT' is a path or url to a directory containing tokenizer files.\n",
            "2019-09-23 14:37:09 - loading file output/training_nli_bert-2019-09-22_21-50-05/0_BERT/vocab.txt\n",
            "2019-09-23 14:37:09 - loading file output/training_nli_bert-2019-09-22_21-50-05/0_BERT/added_tokens.json\n",
            "2019-09-23 14:37:09 - loading file output/training_nli_bert-2019-09-22_21-50-05/0_BERT/special_tokens_map.json\n",
            "2019-09-23 14:37:09 - Use pytorch device: cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert dataset: 100%|██████████| 1379/1379 [00:00<00:00, 3732.76it/s]\n",
            "Convert Evaluating:   3%|▎         | 3/87 [00:00<00:03, 27.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 14:37:10 - Num sentences: 1379\n",
            "2019-09-23 14:37:10 - Sentences 0 longer than max_seqence_length: 0\n",
            "2019-09-23 14:37:10 - Sentences 1 longer than max_seqence_length: 0\n",
            "2019-09-23 14:37:10 - Evaluation the model on  dataset:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Convert Evaluating: 100%|██████████| 87/87 [00:04<00:00, 20.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 14:37:14 - Cosine-Similarity :\tPearson: 0.6995\tSpearman: 0.7248\n",
            "2019-09-23 14:37:14 - Manhattan-Distance:\tPearson: 0.7311\tSpearman: 0.7258\n",
            "2019-09-23 14:37:14 - Euclidean-Distance:\tPearson: 0.7307\tSpearman: 0.7259\n",
            "2019-09-23 14:37:14 - Dot-Product-Similarity:\tPearson: 0.6929\tSpearman: 0.7024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7259206832532674"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riaXDNpR96wL",
        "colab_type": "text"
      },
      "source": [
        "## Tatoeba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDrDqNIc96wO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TatoebaReader:\n",
        "    \"\"\"Reads in a plain text file, in which every line contains one \n",
        "    sentence.\"\"\"\n",
        "    def __init__(self, file_path: Path):\n",
        "        self.file_path = file_path\n",
        "\n",
        "    def get_examples(self):\n",
        "        examples = []        \n",
        "        with open(self.file_path) as fin:\n",
        "            for i, line in enumerate(fin.readlines()):\n",
        "                examples.append(InputExample(guid=i, texts=[line], label=0))                \n",
        "        return examples\n",
        "\n",
        "TATOEBA_PATH = Path(\"../data/tatoeba/v1/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKue7Sup96wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_language_pair(model, pair_name=\"cmn-eng\", batch_size=32):\n",
        "    lang_1, lang_2 = pair_name.split(\"-\")\n",
        "    reader_1 = TatoebaReader(TATOEBA_PATH / f\"tatoeba.{pair_name}.{lang_1}\")\n",
        "    ds_1 = SentencesDataset(reader_1.get_examples(), model=model)\n",
        "    loader_1 = DataLoader(\n",
        "        ds_1, shuffle=False, batch_size=batch_size, \n",
        "        collate_fn=model.smart_batching_collate)\n",
        "\n",
        "    reader_2 = TatoebaReader(TATOEBA_PATH / f\"tatoeba.{pair_name}.{lang_2}\")\n",
        "    ds_2 = SentencesDataset(reader_2.get_examples(), model=model)\n",
        "    loader_2 = DataLoader(\n",
        "        ds_2, shuffle=False, batch_size=batch_size, \n",
        "        collate_fn=model.smart_batching_collate)\n",
        "    \n",
        "    model.eval()\n",
        "    emb_1, emb_2 = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader_1:\n",
        "            emb_1.append(model(\n",
        "                batch_to_device(batch, \"cuda\")[0][0]\n",
        "            )['sentence_embedding'])\n",
        "        for batch in loader_2:\n",
        "            emb_2.append(model(\n",
        "                batch_to_device(batch, \"cuda\")[0][0]\n",
        "            )['sentence_embedding'])\n",
        "    emb_1 = torch.cat(emb_1).cpu().numpy()\n",
        "    emb_2 = torch.cat(emb_2).cpu().numpy()\n",
        "    \n",
        "    idx_1 = faiss.IndexFlatL2(emb_1.shape[1])\n",
        "    faiss.normalize_L2(emb_1)\n",
        "    idx_1.add(emb_1)\n",
        "    idx_2 = faiss.IndexFlatL2(emb_2.shape[1])\n",
        "    faiss.normalize_L2(emb_2)\n",
        "    idx_2.add(emb_2)\n",
        "    \n",
        "    results = []\n",
        "    _, match = idx_2.search(x=emb_1, k=1)\n",
        "    results.append((\n",
        "        lang_1, lang_2,\n",
        "        np.sum(match[:, 0] == np.arange(len(emb_1))),\n",
        "        len(emb_1)\n",
        "    ))\n",
        "    _, match = idx_1.search(x=emb_2, k=1)\n",
        "    results.append((\n",
        "        lang_2, lang_1,\n",
        "        np.sum(match[:, 0] == np.arange(len(emb_2))),\n",
        "        len(emb_2)\n",
        "    ))\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzZETjCq96wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PAIRS = [\"ita-eng\", \"spa-eng\", \"fra-eng\", \"deu-eng\", \"rus-eng\", \"jpn-eng\", \"cmn-eng\", \"hin-eng\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyV5PaDZ96w8",
        "colab_type": "text"
      },
      "source": [
        "### Fine-tuned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rzM3mZx96w_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SentenceTransformer('output/training_nli_bert-2019-09-22_21-50-05')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPb-_6Kq96xR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []\n",
        "for pair in PAIRS:\n",
        "    results += evaluate_language_pair(model, pair_name=pair, batch_size=50)\n",
        "df_finetuned = pd.DataFrame(results, columns=[\"from\", \"to\", \"correct\", \"total\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EugaKMWF96xe",
        "colab_type": "code",
        "colab": {},
        "outputId": "01c00aaf-df62-45cf-d09f-8868f3fd7152"
      },
      "source": [
        "df_finetuned"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>correct</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>ita</td>\n",
              "      <td>eng</td>\n",
              "      <td>498</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>eng</td>\n",
              "      <td>ita</td>\n",
              "      <td>516</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>spa</td>\n",
              "      <td>eng</td>\n",
              "      <td>532</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>eng</td>\n",
              "      <td>spa</td>\n",
              "      <td>554</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>fra</td>\n",
              "      <td>eng</td>\n",
              "      <td>511</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>eng</td>\n",
              "      <td>fra</td>\n",
              "      <td>508</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>deu</td>\n",
              "      <td>eng</td>\n",
              "      <td>513</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>eng</td>\n",
              "      <td>deu</td>\n",
              "      <td>499</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>rus</td>\n",
              "      <td>eng</td>\n",
              "      <td>498</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>eng</td>\n",
              "      <td>rus</td>\n",
              "      <td>488</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>jpn</td>\n",
              "      <td>eng</td>\n",
              "      <td>378</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>eng</td>\n",
              "      <td>jpn</td>\n",
              "      <td>369</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>cmn</td>\n",
              "      <td>eng</td>\n",
              "      <td>644</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>eng</td>\n",
              "      <td>cmn</td>\n",
              "      <td>597</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>hin</td>\n",
              "      <td>eng</td>\n",
              "      <td>95</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>eng</td>\n",
              "      <td>hin</td>\n",
              "      <td>126</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   from   to  correct  total\n",
              "0   ita  eng      498   1000\n",
              "1   eng  ita      516   1000\n",
              "2   spa  eng      532   1000\n",
              "3   eng  spa      554   1000\n",
              "4   fra  eng      511   1000\n",
              "5   eng  fra      508   1000\n",
              "6   deu  eng      513   1000\n",
              "7   eng  deu      499   1000\n",
              "8   rus  eng      498   1000\n",
              "9   eng  rus      488   1000\n",
              "10  jpn  eng      378   1000\n",
              "11  eng  jpn      369   1000\n",
              "12  cmn  eng      644   1000\n",
              "13  eng  cmn      597   1000\n",
              "14  hin  eng       95   1000\n",
              "15  eng  hin      126   1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBHH1qIu96xt",
        "colab_type": "text"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDNS0zHA96x8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embedding_model = models.BERT('../models/bert-base-multilingual-cased/')\n",
        "# Apply mean pooling to get one fixed sized sentence vector\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=True,\n",
        "                               pooling_mode_cls_token=False,\n",
        "                               pooling_mode_max_tokens=False)\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OmJeV76q96yi",
        "colab_type": "code",
        "colab": {},
        "outputId": "cca6cae2-7e0f-433f-d65a-dc066b2a7e0d"
      },
      "source": [
        "results = []\n",
        "for pair in PAIRS:\n",
        "    results += evaluate_language_pair(model, pair_name=pair, batch_size=50)\n",
        "df_baseline_mean = pd.DataFrame(results, columns=[\"from\", \"to\", \"correct\", \"total\"])\n",
        "df_baseline_mean"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>correct</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>ita</td>\n",
              "      <td>eng</td>\n",
              "      <td>500</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>eng</td>\n",
              "      <td>ita</td>\n",
              "      <td>383</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>spa</td>\n",
              "      <td>eng</td>\n",
              "      <td>521</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>eng</td>\n",
              "      <td>spa</td>\n",
              "      <td>477</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>fra</td>\n",
              "      <td>eng</td>\n",
              "      <td>482</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>eng</td>\n",
              "      <td>fra</td>\n",
              "      <td>385</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>deu</td>\n",
              "      <td>eng</td>\n",
              "      <td>488</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>eng</td>\n",
              "      <td>deu</td>\n",
              "      <td>478</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>rus</td>\n",
              "      <td>eng</td>\n",
              "      <td>430</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>eng</td>\n",
              "      <td>rus</td>\n",
              "      <td>415</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>jpn</td>\n",
              "      <td>eng</td>\n",
              "      <td>268</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>eng</td>\n",
              "      <td>jpn</td>\n",
              "      <td>290</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>cmn</td>\n",
              "      <td>eng</td>\n",
              "      <td>510</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>eng</td>\n",
              "      <td>cmn</td>\n",
              "      <td>522</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>hin</td>\n",
              "      <td>eng</td>\n",
              "      <td>84</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>eng</td>\n",
              "      <td>hin</td>\n",
              "      <td>113</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   from   to  correct  total\n",
              "0   ita  eng      500   1000\n",
              "1   eng  ita      383   1000\n",
              "2   spa  eng      521   1000\n",
              "3   eng  spa      477   1000\n",
              "4   fra  eng      482   1000\n",
              "5   eng  fra      385   1000\n",
              "6   deu  eng      488   1000\n",
              "7   eng  deu      478   1000\n",
              "8   rus  eng      430   1000\n",
              "9   eng  rus      415   1000\n",
              "10  jpn  eng      268   1000\n",
              "11  eng  jpn      290   1000\n",
              "12  cmn  eng      510   1000\n",
              "13  eng  cmn      522   1000\n",
              "14  hin  eng       84   1000\n",
              "15  eng  hin      113   1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaIBqbeE96y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embedding_model = models.BERT('../models/bert-base-multilingual-cased/')\n",
        "# Apply mean pooling to get one fixed sized sentence vector\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=False,\n",
        "                               pooling_mode_cls_token=True,\n",
        "                               pooling_mode_max_tokens=False)\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpBZ_m5F96zR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []\n",
        "for pair in PAIRS:\n",
        "    results += evaluate_language_pair(model, pair_name=pair, batch_size=50)\n",
        "df_baseline_cls = pd.DataFrame(results, columns=[\"from\", \"to\", \"correct\", \"total\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Ucvw7Z96zc",
        "colab_type": "code",
        "colab": {},
        "outputId": "097d7ded-8e86-4990-b451-89e922fa42ea"
      },
      "source": [
        "df_baseline_cls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>correct</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>ita</td>\n",
              "      <td>eng</td>\n",
              "      <td>121</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>eng</td>\n",
              "      <td>ita</td>\n",
              "      <td>224</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>spa</td>\n",
              "      <td>eng</td>\n",
              "      <td>109</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>eng</td>\n",
              "      <td>spa</td>\n",
              "      <td>291</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>fra</td>\n",
              "      <td>eng</td>\n",
              "      <td>169</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>eng</td>\n",
              "      <td>fra</td>\n",
              "      <td>230</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>deu</td>\n",
              "      <td>eng</td>\n",
              "      <td>115</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>eng</td>\n",
              "      <td>deu</td>\n",
              "      <td>263</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>rus</td>\n",
              "      <td>eng</td>\n",
              "      <td>165</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>eng</td>\n",
              "      <td>rus</td>\n",
              "      <td>213</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>jpn</td>\n",
              "      <td>eng</td>\n",
              "      <td>85</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>eng</td>\n",
              "      <td>jpn</td>\n",
              "      <td>140</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>cmn</td>\n",
              "      <td>eng</td>\n",
              "      <td>84</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>eng</td>\n",
              "      <td>cmn</td>\n",
              "      <td>282</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>hin</td>\n",
              "      <td>eng</td>\n",
              "      <td>8</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>eng</td>\n",
              "      <td>hin</td>\n",
              "      <td>51</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   from   to  correct  total\n",
              "0   ita  eng      121   1000\n",
              "1   eng  ita      224   1000\n",
              "2   spa  eng      109   1000\n",
              "3   eng  spa      291   1000\n",
              "4   fra  eng      169   1000\n",
              "5   eng  fra      230   1000\n",
              "6   deu  eng      115   1000\n",
              "7   eng  deu      263   1000\n",
              "8   rus  eng      165   1000\n",
              "9   eng  rus      213   1000\n",
              "10  jpn  eng       85   1000\n",
              "11  eng  jpn      140   1000\n",
              "12  cmn  eng       84   1000\n",
              "13  eng  cmn      282   1000\n",
              "14  hin  eng        8   1000\n",
              "15  eng  hin       51   1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgqGKlPl960O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embedding_model = models.BERT('../models/bert-base-multilingual-cased/')\n",
        "# Apply mean pooling to get one fixed sized sentence vector\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=False,\n",
        "                               pooling_mode_cls_token=False,\n",
        "                               pooling_mode_max_tokens=True)\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed_DYiS7960U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []\n",
        "for pair in PAIRS:\n",
        "    results += evaluate_language_pair(model, pair_name=pair, batch_size=50)\n",
        "df_baseline_max = pd.DataFrame(results, columns=[\"from\", \"to\", \"correct\", \"total\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juVOLvpG960Z",
        "colab_type": "code",
        "colab": {},
        "outputId": "ac988706-6b98-48f6-b36e-05ab36172be6"
      },
      "source": [
        "df_baseline_max"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>correct</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>ita</td>\n",
              "      <td>eng</td>\n",
              "      <td>295</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>eng</td>\n",
              "      <td>ita</td>\n",
              "      <td>373</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>spa</td>\n",
              "      <td>eng</td>\n",
              "      <td>320</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>eng</td>\n",
              "      <td>spa</td>\n",
              "      <td>427</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>fra</td>\n",
              "      <td>eng</td>\n",
              "      <td>200</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>eng</td>\n",
              "      <td>fra</td>\n",
              "      <td>335</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>deu</td>\n",
              "      <td>eng</td>\n",
              "      <td>193</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>eng</td>\n",
              "      <td>deu</td>\n",
              "      <td>363</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>rus</td>\n",
              "      <td>eng</td>\n",
              "      <td>216</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>eng</td>\n",
              "      <td>rus</td>\n",
              "      <td>320</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>jpn</td>\n",
              "      <td>eng</td>\n",
              "      <td>69</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>eng</td>\n",
              "      <td>jpn</td>\n",
              "      <td>198</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>cmn</td>\n",
              "      <td>eng</td>\n",
              "      <td>290</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>eng</td>\n",
              "      <td>cmn</td>\n",
              "      <td>365</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>hin</td>\n",
              "      <td>eng</td>\n",
              "      <td>14</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>eng</td>\n",
              "      <td>hin</td>\n",
              "      <td>76</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   from   to  correct  total\n",
              "0   ita  eng      295   1000\n",
              "1   eng  ita      373   1000\n",
              "2   spa  eng      320   1000\n",
              "3   eng  spa      427   1000\n",
              "4   fra  eng      200   1000\n",
              "5   eng  fra      335   1000\n",
              "6   deu  eng      193   1000\n",
              "7   eng  deu      363   1000\n",
              "8   rus  eng      216   1000\n",
              "9   eng  rus      320   1000\n",
              "10  jpn  eng       69   1000\n",
              "11  eng  jpn      198   1000\n",
              "12  cmn  eng      290   1000\n",
              "13  eng  cmn      365   1000\n",
              "14  hin  eng       14   1000\n",
              "15  eng  hin       76   1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfh2oKWj960i",
        "colab_type": "text"
      },
      "source": [
        "### Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGR7h4Xu960k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_baseline_mean[\"err_mean\"] = 1 - df_baseline_mean[\"correct\"] / df_baseline_mean[\"total\"]\n",
        "df_baseline_max[\"err_max\"] = 1 - df_baseline_max[\"correct\"] / df_baseline_max[\"total\"]\n",
        "df_baseline_cls[\"err_cls\"] = 1 - df_baseline_cls[\"correct\"] / df_baseline_cls[\"total\"]\n",
        "df_finetuned[\"err_finetuned\"] = 1 - df_finetuned[\"correct\"] / df_finetuned[\"total\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAyucWBj960p",
        "colab_type": "code",
        "colab": {},
        "outputId": "0b59c233-db1b-4d77-c6c4-a02df41d2185"
      },
      "source": [
        "df_err = pd.concat([\n",
        "    df.set_index([\"from\", \"to\"]).drop([\"correct\", \"total\"], axis=1)\n",
        "    for df in (df_baseline_mean, df_baseline_max, df_baseline_cls, df_finetuned)\n",
        "], axis=1)\n",
        "df_err"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>err_mean</th>\n",
              "      <th>err_max</th>\n",
              "      <th>err_cls</th>\n",
              "      <th>err_finetuned</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>ita</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.705</td>\n",
              "      <td>0.879</td>\n",
              "      <td>0.502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>ita</td>\n",
              "      <td>0.617</td>\n",
              "      <td>0.627</td>\n",
              "      <td>0.776</td>\n",
              "      <td>0.484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>spa</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.479</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.891</td>\n",
              "      <td>0.468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>spa</td>\n",
              "      <td>0.523</td>\n",
              "      <td>0.573</td>\n",
              "      <td>0.709</td>\n",
              "      <td>0.446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>fra</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.518</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.831</td>\n",
              "      <td>0.489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>fra</td>\n",
              "      <td>0.615</td>\n",
              "      <td>0.665</td>\n",
              "      <td>0.770</td>\n",
              "      <td>0.492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>deu</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.512</td>\n",
              "      <td>0.807</td>\n",
              "      <td>0.885</td>\n",
              "      <td>0.487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>deu</td>\n",
              "      <td>0.522</td>\n",
              "      <td>0.637</td>\n",
              "      <td>0.737</td>\n",
              "      <td>0.501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>rus</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.570</td>\n",
              "      <td>0.784</td>\n",
              "      <td>0.835</td>\n",
              "      <td>0.502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>rus</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.787</td>\n",
              "      <td>0.512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>jpn</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.732</td>\n",
              "      <td>0.931</td>\n",
              "      <td>0.915</td>\n",
              "      <td>0.622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>jpn</td>\n",
              "      <td>0.710</td>\n",
              "      <td>0.802</td>\n",
              "      <td>0.860</td>\n",
              "      <td>0.631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>cmn</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.490</td>\n",
              "      <td>0.710</td>\n",
              "      <td>0.916</td>\n",
              "      <td>0.356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>cmn</td>\n",
              "      <td>0.478</td>\n",
              "      <td>0.635</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>hin</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.916</td>\n",
              "      <td>0.986</td>\n",
              "      <td>0.992</td>\n",
              "      <td>0.905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>hin</td>\n",
              "      <td>0.887</td>\n",
              "      <td>0.924</td>\n",
              "      <td>0.949</td>\n",
              "      <td>0.874</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          err_mean  err_max  err_cls  err_finetuned\n",
              "from to                                            \n",
              "ita  eng     0.500    0.705    0.879          0.502\n",
              "eng  ita     0.617    0.627    0.776          0.484\n",
              "spa  eng     0.479    0.680    0.891          0.468\n",
              "eng  spa     0.523    0.573    0.709          0.446\n",
              "fra  eng     0.518    0.800    0.831          0.489\n",
              "eng  fra     0.615    0.665    0.770          0.492\n",
              "deu  eng     0.512    0.807    0.885          0.487\n",
              "eng  deu     0.522    0.637    0.737          0.501\n",
              "rus  eng     0.570    0.784    0.835          0.502\n",
              "eng  rus     0.585    0.680    0.787          0.512\n",
              "jpn  eng     0.732    0.931    0.915          0.622\n",
              "eng  jpn     0.710    0.802    0.860          0.631\n",
              "cmn  eng     0.490    0.710    0.916          0.356\n",
              "eng  cmn     0.478    0.635    0.718          0.403\n",
              "hin  eng     0.916    0.986    0.992          0.905\n",
              "eng  hin     0.887    0.924    0.949          0.874"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICBqejWA960y",
        "colab_type": "code",
        "colab": {},
        "outputId": "23d124d1-fe5c-4427-f533-afc84d9ec441"
      },
      "source": [
        "df_err[\"diff_mean\"] = df_err[\"err_finetuned\"] - df_err[\"err_mean\"]\n",
        "df_err[\"diff_pct_mean\"] = df_err[\"diff_mean\"] / df_err[\"err_mean\"]\n",
        "df_err[\"diff_max\"] = df_err[\"err_finetuned\"] - df_err[\"err_max\"]\n",
        "df_err[\"diff_pct_max\"] = df_err[\"diff_max\"] / df_err[\"err_max\"]\n",
        "df_err[\"diff_cls\"] = df_err[\"err_finetuned\"] - df_err[\"err_cls\"]\n",
        "df_err[\"diff_pct_cls\"] = df_err[\"diff_cls\"] / df_err[\"err_cls\"]\n",
        "df_err"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>err_mean</th>\n",
              "      <th>err_max</th>\n",
              "      <th>err_cls</th>\n",
              "      <th>err_finetuned</th>\n",
              "      <th>diff_mean</th>\n",
              "      <th>diff_max</th>\n",
              "      <th>diff_cls</th>\n",
              "      <th>diff_pct_mean</th>\n",
              "      <th>diff_pct_max</th>\n",
              "      <th>diff_pct_cls</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>ita</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.705</td>\n",
              "      <td>0.879</td>\n",
              "      <td>0.502</td>\n",
              "      <td>0.002</td>\n",
              "      <td>-0.203</td>\n",
              "      <td>-0.377</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>-0.287943</td>\n",
              "      <td>-0.428896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>ita</td>\n",
              "      <td>0.617</td>\n",
              "      <td>0.627</td>\n",
              "      <td>0.776</td>\n",
              "      <td>0.484</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>-0.143</td>\n",
              "      <td>-0.292</td>\n",
              "      <td>-0.215559</td>\n",
              "      <td>-0.228070</td>\n",
              "      <td>-0.376289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>spa</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.479</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.891</td>\n",
              "      <td>0.468</td>\n",
              "      <td>-0.011</td>\n",
              "      <td>-0.212</td>\n",
              "      <td>-0.423</td>\n",
              "      <td>-0.022965</td>\n",
              "      <td>-0.311765</td>\n",
              "      <td>-0.474747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>spa</td>\n",
              "      <td>0.523</td>\n",
              "      <td>0.573</td>\n",
              "      <td>0.709</td>\n",
              "      <td>0.446</td>\n",
              "      <td>-0.077</td>\n",
              "      <td>-0.127</td>\n",
              "      <td>-0.263</td>\n",
              "      <td>-0.147228</td>\n",
              "      <td>-0.221640</td>\n",
              "      <td>-0.370945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>fra</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.518</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.831</td>\n",
              "      <td>0.489</td>\n",
              "      <td>-0.029</td>\n",
              "      <td>-0.311</td>\n",
              "      <td>-0.342</td>\n",
              "      <td>-0.055985</td>\n",
              "      <td>-0.388750</td>\n",
              "      <td>-0.411552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>fra</td>\n",
              "      <td>0.615</td>\n",
              "      <td>0.665</td>\n",
              "      <td>0.770</td>\n",
              "      <td>0.492</td>\n",
              "      <td>-0.123</td>\n",
              "      <td>-0.173</td>\n",
              "      <td>-0.278</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>-0.260150</td>\n",
              "      <td>-0.361039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>deu</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.512</td>\n",
              "      <td>0.807</td>\n",
              "      <td>0.885</td>\n",
              "      <td>0.487</td>\n",
              "      <td>-0.025</td>\n",
              "      <td>-0.320</td>\n",
              "      <td>-0.398</td>\n",
              "      <td>-0.048828</td>\n",
              "      <td>-0.396530</td>\n",
              "      <td>-0.449718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>deu</td>\n",
              "      <td>0.522</td>\n",
              "      <td>0.637</td>\n",
              "      <td>0.737</td>\n",
              "      <td>0.501</td>\n",
              "      <td>-0.021</td>\n",
              "      <td>-0.136</td>\n",
              "      <td>-0.236</td>\n",
              "      <td>-0.040230</td>\n",
              "      <td>-0.213501</td>\n",
              "      <td>-0.320217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>rus</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.570</td>\n",
              "      <td>0.784</td>\n",
              "      <td>0.835</td>\n",
              "      <td>0.502</td>\n",
              "      <td>-0.068</td>\n",
              "      <td>-0.282</td>\n",
              "      <td>-0.333</td>\n",
              "      <td>-0.119298</td>\n",
              "      <td>-0.359694</td>\n",
              "      <td>-0.398802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>rus</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.787</td>\n",
              "      <td>0.512</td>\n",
              "      <td>-0.073</td>\n",
              "      <td>-0.168</td>\n",
              "      <td>-0.275</td>\n",
              "      <td>-0.124786</td>\n",
              "      <td>-0.247059</td>\n",
              "      <td>-0.349428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>jpn</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.732</td>\n",
              "      <td>0.931</td>\n",
              "      <td>0.915</td>\n",
              "      <td>0.622</td>\n",
              "      <td>-0.110</td>\n",
              "      <td>-0.309</td>\n",
              "      <td>-0.293</td>\n",
              "      <td>-0.150273</td>\n",
              "      <td>-0.331901</td>\n",
              "      <td>-0.320219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>jpn</td>\n",
              "      <td>0.710</td>\n",
              "      <td>0.802</td>\n",
              "      <td>0.860</td>\n",
              "      <td>0.631</td>\n",
              "      <td>-0.079</td>\n",
              "      <td>-0.171</td>\n",
              "      <td>-0.229</td>\n",
              "      <td>-0.111268</td>\n",
              "      <td>-0.213217</td>\n",
              "      <td>-0.266279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>cmn</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.490</td>\n",
              "      <td>0.710</td>\n",
              "      <td>0.916</td>\n",
              "      <td>0.356</td>\n",
              "      <td>-0.134</td>\n",
              "      <td>-0.354</td>\n",
              "      <td>-0.560</td>\n",
              "      <td>-0.273469</td>\n",
              "      <td>-0.498592</td>\n",
              "      <td>-0.611354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>cmn</td>\n",
              "      <td>0.478</td>\n",
              "      <td>0.635</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.403</td>\n",
              "      <td>-0.075</td>\n",
              "      <td>-0.232</td>\n",
              "      <td>-0.315</td>\n",
              "      <td>-0.156904</td>\n",
              "      <td>-0.365354</td>\n",
              "      <td>-0.438719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>hin</td>\n",
              "      <td>eng</td>\n",
              "      <td>0.916</td>\n",
              "      <td>0.986</td>\n",
              "      <td>0.992</td>\n",
              "      <td>0.905</td>\n",
              "      <td>-0.011</td>\n",
              "      <td>-0.081</td>\n",
              "      <td>-0.087</td>\n",
              "      <td>-0.012009</td>\n",
              "      <td>-0.082150</td>\n",
              "      <td>-0.087702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>eng</td>\n",
              "      <td>hin</td>\n",
              "      <td>0.887</td>\n",
              "      <td>0.924</td>\n",
              "      <td>0.949</td>\n",
              "      <td>0.874</td>\n",
              "      <td>-0.013</td>\n",
              "      <td>-0.050</td>\n",
              "      <td>-0.075</td>\n",
              "      <td>-0.014656</td>\n",
              "      <td>-0.054113</td>\n",
              "      <td>-0.079031</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          err_mean  err_max  err_cls  err_finetuned  diff_mean  diff_max  \\\n",
              "from to                                                                    \n",
              "ita  eng     0.500    0.705    0.879          0.502      0.002    -0.203   \n",
              "eng  ita     0.617    0.627    0.776          0.484     -0.133    -0.143   \n",
              "spa  eng     0.479    0.680    0.891          0.468     -0.011    -0.212   \n",
              "eng  spa     0.523    0.573    0.709          0.446     -0.077    -0.127   \n",
              "fra  eng     0.518    0.800    0.831          0.489     -0.029    -0.311   \n",
              "eng  fra     0.615    0.665    0.770          0.492     -0.123    -0.173   \n",
              "deu  eng     0.512    0.807    0.885          0.487     -0.025    -0.320   \n",
              "eng  deu     0.522    0.637    0.737          0.501     -0.021    -0.136   \n",
              "rus  eng     0.570    0.784    0.835          0.502     -0.068    -0.282   \n",
              "eng  rus     0.585    0.680    0.787          0.512     -0.073    -0.168   \n",
              "jpn  eng     0.732    0.931    0.915          0.622     -0.110    -0.309   \n",
              "eng  jpn     0.710    0.802    0.860          0.631     -0.079    -0.171   \n",
              "cmn  eng     0.490    0.710    0.916          0.356     -0.134    -0.354   \n",
              "eng  cmn     0.478    0.635    0.718          0.403     -0.075    -0.232   \n",
              "hin  eng     0.916    0.986    0.992          0.905     -0.011    -0.081   \n",
              "eng  hin     0.887    0.924    0.949          0.874     -0.013    -0.050   \n",
              "\n",
              "          diff_cls  diff_pct_mean  diff_pct_max  diff_pct_cls  \n",
              "from to                                                        \n",
              "ita  eng    -0.377       0.004000     -0.287943     -0.428896  \n",
              "eng  ita    -0.292      -0.215559     -0.228070     -0.376289  \n",
              "spa  eng    -0.423      -0.022965     -0.311765     -0.474747  \n",
              "eng  spa    -0.263      -0.147228     -0.221640     -0.370945  \n",
              "fra  eng    -0.342      -0.055985     -0.388750     -0.411552  \n",
              "eng  fra    -0.278      -0.200000     -0.260150     -0.361039  \n",
              "deu  eng    -0.398      -0.048828     -0.396530     -0.449718  \n",
              "eng  deu    -0.236      -0.040230     -0.213501     -0.320217  \n",
              "rus  eng    -0.333      -0.119298     -0.359694     -0.398802  \n",
              "eng  rus    -0.275      -0.124786     -0.247059     -0.349428  \n",
              "jpn  eng    -0.293      -0.150273     -0.331901     -0.320219  \n",
              "eng  jpn    -0.229      -0.111268     -0.213217     -0.266279  \n",
              "cmn  eng    -0.560      -0.273469     -0.498592     -0.611354  \n",
              "eng  cmn    -0.315      -0.156904     -0.365354     -0.438719  \n",
              "hin  eng    -0.087      -0.012009     -0.082150     -0.087702  \n",
              "eng  hin    -0.075      -0.014656     -0.054113     -0.079031  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acXr1gUS9604",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_err.to_csv(\"df_err.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZVyVpqX961I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}